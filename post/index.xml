<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | zak</title>
    <link>/post/</link>
      <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>ja-JP</language><copyright>© zak 2019</copyright><lastBuildDate>Fri, 01 Nov 2019 14:07:56 +0900</lastBuildDate>
    <image>
      <url>/img/icon-1080.png</url>
      <title>Posts</title>
      <link>/post/</link>
    </image>
    
    <item>
      <title>Internal of Golang Concurrency Primitives</title>
      <link>/post/internal-of-golang-concurrency-primitives/</link>
      <pubDate>Fri, 01 Nov 2019 14:07:56 +0900</pubDate>
      <guid>/post/internal-of-golang-concurrency-primitives/</guid>
      <description>

&lt;h2 id=&#34;並行処理-並列処理&#34;&gt;並行処理？並列処理？&lt;/h2&gt;

&lt;p&gt;並行処理とか並列処理って一体なんなのでしょう．&lt;/p&gt;

&lt;p&gt;黎明期の計算機では，並行処理だの並列処理だのなんてことは，一切考えていませんでした．入力された命令を1つずつ，真面目に実行していくことで計算を実行していたのです．黎明期の計算機は，人間が紙と鉛筆でちんたら計算をするよりも，何倍も高速にかつ正確に計算をすることができたので，とても人気になりました．ただ，その当時の計算機は物理的にサイズもデカくて高価なものでした．なので，計算機を導入・設置できるのは大学などのお金と部屋が余っている組織ぐらいしかなかったわけです．&lt;/p&gt;

&lt;p&gt;大学に計算機が設置されると，大学の研究者たちは喜びました．これで面倒な手計算から解放されるわけですからそりゃそうでしょう．みんなでこぞって計算機を使いたくなります．でも「計算機を利用したい研究者の人数」が「設置してある計算機の台数」と比較して圧倒的に多いので，計算機の使用を巡って争奪戦が起こります．だって，当時の計算機は「入力された命令を1つずつ，真面目に実行していく」タイプの計算機なので，他の誰かが計算機に計算をさせている間は，他の研究者はその計算機を使うことができないからです．そんなの不便すぎます．せっかく便利でしかもめちゃんこ高価な計算機が設置してあるのに，しかも使いたい人はたくさんいるのに使わせてあげられないなんて，もう不満タラタラです．そこで研究者たちは考えました．&lt;/p&gt;

&lt;p&gt;「どうやって1台の計算機を複数人で共有して使うことができるだろうか？」&lt;/p&gt;

&lt;p&gt;「1台の計算機で複数のタスクを処理するためにはどんな仕組みが必要なんだろうか？」&lt;/p&gt;

&lt;p&gt;ここからoperating systemとかprocessとかいろんな概念が確立されていくわけです．&lt;/p&gt;

&lt;p&gt;「並行」というのは，英語ではconcurrentに相当し，「1台のマシンで複数のタスクを同時に実行している（ように見える）様」を意味します．concurrentな処理は「限られたリソースを有効活用すること」を目的としていて，現在の計算機では「同時に処理しているように見せるために，複数のタスクを時間的に細切れにして全部のタスクをちょっとずつ進める」ことでconcurrentな処理を実現しています．&lt;/p&gt;

&lt;p&gt;一方で，似たような概念として「並列」というものもあります．英語ではparallelに相当し，「複数台のマシンで1つのタスクを実行している様」を意味します．parallelな処理は「（複数のマシンという）豊富なリソースを利用して1つのタスクを高速に実行すること」を目的としていて，concurrentとは目的が違います．&lt;/p&gt;

&lt;h2 id=&#34;concurrentなプログラム&#34;&gt;concurrentなプログラム&lt;/h2&gt;

&lt;p&gt;ここまで計算機の進化の歴史を本当にざっくり見てみましたが，じゃあconcurrentという概念がプログラムとどう絡んでいくのでしょうか．&lt;/p&gt;

&lt;p&gt;プログラムというのは大体「CPUでの演算」「データのI/O」「ネットワーキング」を部品として構成されています．それぞれの部品には特徴があって，「CPUでの演算」はとても高速に実行できるけれども，「データのI/O」と「ネットーワーキング」は（「CPUでの演算」と比較して）桁違いに，本当に桁違いに時間がかかります．もし計算機が「入力された命令を1つずつ，真面目に実行していく」方式で動いていたとすると，「データのI/O」と「ネットーワーキング」に取り組んでいる間，計算機はうんともすんとも言わずに黙り込んでしまうことになります．これは明らかに無駄です．CPUは何も計算を進めないでただ存在しているだけになるわけです．&lt;/p&gt;

&lt;p&gt;concurrentという概念の背景には「どうやって1台の計算機を複数人で共有して使うことができるだろうか？」という問題があったわけです．この問題意識が一歩進むと，「1台の計算機で複数のタスクを処理するためにはどんな仕組みが必要なんだろうか？」となり，さらに一歩進んで「（複数のタスクで構成される）1つのプログラムを1台のCPUで効率的に処理するためにはどういう仕組みが必要なんだろう？&amp;hellip;そうだ！CPUが暇な時間帯には別の仕事をさせよう！」となるわけです．&lt;/p&gt;

&lt;p&gt;「時間がかかってしまう処理をやっている間に，他にできる計算をCPUにやらせよう」というのがconcurrentなプログラムを書きたい理由です．だってそうした方がやりたいこと早く終わるでしょう．しかもPersonalな計算機が世の中に普及して「計算機はより高速にユーザーの動作に応答しなきゃいけない（うんともすんとも言わない計算機は嫌われてる）」し「ユーザーは大抵の場合音楽聴きながらメールチェックしつつYoutubeで動画も見たいワガママな存在」なので，CPUに暇な時間なんてものはないわけですよ．&lt;/p&gt;

&lt;p&gt;「プログラムはconcurrentに実行されるべき」となるとconcurrentなプログラムを記述して，それを実際にconcurrentに実行する機構が必要になります．&lt;/p&gt;

&lt;p&gt;「実際にconcurrentに実行する機構」についてはOperating Systemが頑張って，プログラムがconcurrentに実行されるように実行環境を提供します．Operating Systemは結構頑張るのですが，やっぱり頑固なハードウェアさんとやりとりしないといけないので，相当大変そうです．提供してくれる実行環境の効率にも限度がありそうです．&lt;/p&gt;

&lt;p&gt;「concurrentなプログラムを記述」するところについては，プログラミング言語の守備範囲なわけですが，いろんな言語がいろんなアプローチを取って，concurrentなプログラムをより簡単に書けるように，プログラム開発者に部品primitiveを提供してくれます．&lt;/p&gt;

&lt;p&gt;でも古参のプログラミング言語たちは，そのデザインの根幹に「プログラムがconcurrentに実行される」とか想定していないわけで，いざやろうとすると不自然なところとかがやっぱりでてきてしまいます．なのでgolangは，言語のデザインの段階でconcurrencyを考慮した言語として誕生しました．そうすれば，concurrentなプログラムがより直感的にわかりやすく書けるようになるわけです．&lt;/p&gt;

&lt;h2 id=&#34;goroutineとchannel&#34;&gt;goroutineとchannel&lt;/h2&gt;

&lt;p&gt;golangはconcurrentなプログラムを書くためのprimitiveとしてgoroutineとchannelを提供しています．というのもgolangでは，concurrentなプログラムを「goroutineたちがメッセージをやりとりしながら進行する計算」としてモデル化しているのです．ここで注意しておきたいのが，concurrentなプログラムを表現する別のモデルも考えられるという点です．モデル化にはバリエーションがあるので「goroutineたちがmessage passing」だけが唯一のモデルというわけではないです．&lt;/p&gt;

&lt;p&gt;goroutineというのは，概念的にはOSの提供するプロセスとかスレッドみたいなもので，実行中の処理を抽象化したものです．直感的にはOSのスレッドと思っていてもいいかもしれません．実態はちょっと違うんですけどね．この「抽象化された処理」同士がmessage passingによって情報を共有することでconcurrentな処理が実現できることになります．&lt;/p&gt;

&lt;p&gt;channelというのは，goroutine間でのコミュニケーションをサポートするためにメッセージキューです．&lt;/p&gt;

&lt;p&gt;golangは言語設計の根底にある思想として&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t communicate by sharing memory, share memory by communicating.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;を，掲げています．要するに「goroutineたちは共有メモリを設けるのではなくてmessage passingでコミュニケーションをとる」ように設計しようということです．&lt;/p&gt;

&lt;h2 id=&#34;goroutineとchannelの設計と実装を眺める&#34;&gt;goroutineとchannelの設計と実装を眺める&lt;/h2&gt;

&lt;h3 id=&#34;goroutine&#34;&gt;goroutine&lt;/h3&gt;

&lt;p&gt;goroutineは「実行中の処理を抽象化したもの」と書きましたが，これは具体的には「計算に用いるstackと実行状態を保持している構造体」として実装されています．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;type g struct {
	// Stack parameters.
	// stack describes the actual stack memory: [stack.lo, stack.hi).
	// stackguard0 is the stack pointer compared in the Go stack growth prologue.
	// It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption.
	// stackguard1 is the stack pointer compared in the C stack growth prologue.
	// It is stack.lo+StackGuard on g0 and gsignal stacks.
	// It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash).
	stack       stack   // offset known to runtime/cgo
	stackguard0 uintptr // offset known to liblink
	stackguard1 uintptr // offset known to liblink

	// ,,,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;「それってOSの提供するプロセスとかスレッドと同じじゃないの？」&lt;/p&gt;

&lt;p&gt;それは確かにそうなんですが，goroutineはOSの提供するプロセスとかスレッドと同レベルの存在ではなくて，goroutineは，OSの提供するスレッドに対してM:Nでマッピングされる「golangのruntimeが提供する，ユーザー空間で定義されたスレッド」として存在しています．golangのruntimeはgoroutineを管理していて「いつ，どのgoroutineを実行するか」を決定するschedulerとしての役割も担っています．つまりgolangのruntimeはユーザー空間で動く「ミニOS」のようなものな訳です．とは言いつつも，実際に実行されるためにはOSの提供するスレッドとして実行されなければいけないわけですから，goroutineはスレッドにマッピングされることになります．golangのschedulerはgoroutineとOSのスレッドを，M:Nでマッピングします．つまり複数のgoroutineが複数のOSスレッドとして実行されるわけです．1つのgoroutineが複数のOSスレッドとして実行されるし，1つのOSスレッドでは複数のgoroutineを実行することになります．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;goroutine.jpeg&#34; data-caption=&#34;OS Process v.s. OS Thread v.s. Goroutine&#34;&gt;
&lt;img src=&#34;goroutine.jpeg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    OS Process v.s. OS Thread v.s. Goroutine
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;p&gt;となると，重要なのは「golangのruntimeがどのようなルールでgoroutineの実行計画を立てるのか」です．&lt;/p&gt;

&lt;h4 id=&#34;golangのruntimeによるgoroutineのスケジューリング&#34;&gt;golangのruntimeによるgoroutineのスケジューリング&lt;/h4&gt;

&lt;p&gt;登場するのは&lt;code&gt;M&lt;/code&gt;，&lt;code&gt;G&lt;/code&gt;，&lt;code&gt;P&lt;/code&gt;の三人．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;machineの&lt;code&gt;M&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;OSスレッドに相当する&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;G&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;goroutineの&lt;code&gt;G&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;P&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;processorの&lt;code&gt;P&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;スケジューリングのコンテキスト（次どの&lt;code&gt;G&lt;/code&gt;を実行するのか）を管理している&lt;/li&gt;
&lt;li&gt;具体的に言えば，runnableなgoroutineのキューを管理しているのが&lt;code&gt;P&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;gmp.jpeg&#34; data-caption=&#34;G，M，P&#34;&gt;
&lt;img src=&#34;gmp.jpeg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;code&gt;G&lt;/code&gt;，&lt;code&gt;M&lt;/code&gt;，&lt;code&gt;P&lt;/code&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;p&gt;まず，環境変数&lt;code&gt;GOMAXPROCS&lt;/code&gt;の数だけ&lt;code&gt;M&lt;/code&gt;，&lt;code&gt;P&lt;/code&gt;がセットされます．以下では，&lt;code&gt;GOMAXPROCS = 2&lt;/code&gt;とします．&lt;/p&gt;














&lt;figure&gt;

&lt;img src=&#34;gmp2.jpeg&#34; alt=&#34;&#34; &gt;



&lt;/figure&gt;


&lt;p&gt;runnableな&lt;code&gt;G&lt;/code&gt;が&lt;code&gt;P&lt;/code&gt;にenqueueされ，&lt;code&gt;M&lt;/code&gt;は&lt;code&gt;P&lt;/code&gt;からrunnableな&lt;code&gt;G&lt;/code&gt;を1個取り出して実行します．&lt;/p&gt;














&lt;figure&gt;

&lt;img src=&#34;assignment.gif&#34; alt=&#34;&#34; &gt;



&lt;/figure&gt;


&lt;p&gt;もし，queueにrunnableな&lt;code&gt;G&lt;/code&gt;が0個になってしまったら，他のqueueから半分盗みます．&lt;/p&gt;














&lt;figure&gt;

&lt;img src=&#34;work-stealing.gif&#34; alt=&#34;&#34; &gt;



&lt;/figure&gt;


&lt;p&gt;「自分のqueueが空になったら他の&lt;code&gt;M&lt;/code&gt;の持つ&lt;code&gt;P&lt;/code&gt;から半分奪う」というスケジューリングアルゴリズムはwork stealingアルゴリズムと呼ばれています．golangのruntimeのスケジューラーはこのwork stealingアルゴリズムに従ってgoroutineのスケジューリングを行います．このアルゴリズムはCPUをたくさん使うような処理にスケジューリングには効率的である一方でI/O待ちを伴う処理（&lt;code&gt;syscall&lt;/code&gt;の実行やネットワーク処理）とは相性が悪いです．そのため，いくつかの工夫がされています．&lt;/p&gt;

&lt;p&gt;まず，golangのruntimeに存在しているものを整理します．上で登場した&lt;code&gt;M&lt;/code&gt;，&lt;code&gt;G&lt;/code&gt;，&lt;code&gt;P&lt;/code&gt;の他にruntimeには&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;グローバルキュー

&lt;ul&gt;
&lt;li&gt;各&lt;code&gt;M&lt;/code&gt;-&lt;code&gt;P&lt;/code&gt;に対応するqueueとは別に存在するキュー&lt;/li&gt;
&lt;li&gt;通常&lt;code&gt;G&lt;/code&gt;がrunnableになると&lt;code&gt;P&lt;/code&gt;の持つキューに入るが，いくつかの状況ではこちらに入ります&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/golang/go/blob/15ea61c50ca25295497e78354f7f8397e73e3590/src/runtime/proc.go#L4427:6&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;sysmon&lt;/code&gt;&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;GOMAXPROCS&lt;/code&gt;の数だけの&lt;code&gt;M&lt;/code&gt;と&lt;code&gt;P&lt;/code&gt;の他に，&lt;code&gt;sysmon&lt;/code&gt;という関数を実行し続ける特別な&lt;code&gt;M&lt;/code&gt;が存在しています&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sysmon&lt;/code&gt;の実態は無限ループで，そのループの中で&lt;code&gt;netpoll&lt;/code&gt;のチェックなどを行っています&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;P&lt;/code&gt; Idle List

&lt;ul&gt;
&lt;li&gt;暇な&lt;code&gt;P&lt;/code&gt;のリスト&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt; Idle List

&lt;ul&gt;
&lt;li&gt;暇な&lt;code&gt;M&lt;/code&gt;のリスト&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;syscall-を実行した場合&#34;&gt;&lt;code&gt;syscall&lt;/code&gt;を実行した場合&lt;/h5&gt;

&lt;p&gt;時間のかかる&lt;code&gt;syscall&lt;/code&gt;を実行した場合，&lt;code&gt;sysmon&lt;/code&gt;がそれを検知し，&lt;code&gt;syscall&lt;/code&gt;を発行した&lt;code&gt;G&lt;/code&gt;を実行している&lt;code&gt;M&lt;/code&gt;から&lt;code&gt;P&lt;/code&gt;を切り離し，別の&lt;code&gt;M&lt;/code&gt;にその&lt;code&gt;P&lt;/code&gt;をアタッチして処理を継続させます．
&lt;code&gt;syscall&lt;/code&gt;終了後は，まず&lt;code&gt;P&lt;/code&gt; Idle Listを確認して暇そうにしている&lt;code&gt;P&lt;/code&gt;を自身（&lt;code&gt;M&lt;/code&gt;）にアタッチして処理を進めます．&lt;code&gt;P&lt;/code&gt; Idle Listがからの場合は&lt;code&gt;syscall&lt;/code&gt;を発行した&lt;code&gt;G&lt;/code&gt;をグローバルキューに突っ込み（この&lt;code&gt;G&lt;/code&gt;はいずれGCされる），自身（&lt;code&gt;M&lt;/code&gt;）は&lt;code&gt;M&lt;/code&gt; Idle Listに入ります．&lt;/p&gt;














&lt;figure&gt;

&lt;img src=&#34;syscall.gif&#34; alt=&#34;&#34; &gt;



&lt;/figure&gt;


&lt;h5 id=&#34;ネットワーク処理をした場合&#34;&gt;ネットワーク処理をした場合&lt;/h5&gt;

&lt;p&gt;ネットワーク処理の発生時には&lt;code&gt;netpoller&lt;/code&gt;という仕組みに，ネットワーク処理を実行しているgoroutineが登録され，&lt;code&gt;sysmon&lt;/code&gt;が&lt;code&gt;netpoller&lt;/code&gt;にポーリングします．ネットワーク処理が終了したら&lt;code&gt;netpoller&lt;/code&gt;からグローバルキューに追加されて，&lt;code&gt;M&lt;/code&gt;で続きを実行されるのを待つことになります．&lt;/p&gt;

&lt;p&gt;golangの標準ライブラリが提供するネットワーキングのAPIはブロッキングな処理となっていますが，goroutineはOSスレッドに対してM:Nでマッピングされるため，&lt;code&gt;netpoller&lt;/code&gt;をによってノンブロッキングな処理として実行されることになります．&lt;/p&gt;














&lt;figure&gt;

&lt;img src=&#34;network-read.gif&#34; alt=&#34;&#34; &gt;



&lt;/figure&gt;


&lt;h3 id=&#34;channel&#34;&gt;channel&lt;/h3&gt;

&lt;p&gt;channelはgoroutine間でのメッセージングをサポートするキューです．channelにはいくつかの面白い特徴があります．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;channelはgoroutine-safe

&lt;ul&gt;
&lt;li&gt;複数のgoroutineがあるchannelに同時にアクセスしても問題が発生しないようにロック機構が組み込まれています&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;channelはgoroutine間でFIFOなデータの受け渡しが可能です&lt;/li&gt;
&lt;li&gt;channelはその状況次第ではgoroutineをブロックしたりアンブロックしたりできます

&lt;ul&gt;
&lt;li&gt;バッファ0のchannelはgoroutineを同期させることができます．つまりあるgorotuineがchannelに書き込むと，相手のgoroutineがそれを読み込むまで書き込んだgoroutineの実行はブロックされるし，channelから読み込みたいgoroutineの実行は，相手のgoroutineが何かを書き込むまでブロックされます．&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;channelは&lt;a href=&#34;https://github.com/golang/go/blob/1f3339f441e2053f8efd7ead417761ea319fe790/src/runtime/chan.go#L32:6&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;hchan&lt;/code&gt;&lt;/a&gt;という名前の構造体で実装されています．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;type hchan struct {
	qcount   uint           // total data in the queue
	dataqsiz uint           // size of the circular queue
	buf      unsafe.Pointer // points to an array of dataqsiz elements
	elemsize uint16
	closed   uint32
	elemtype *_type // element type
	sendx    uint   // send index
	recvx    uint   // receive index
	recvq    waitq  // list of recv waiters
	sendq    waitq  // list of send waiters

	// lock protects all fields in hchan, as well as several
	// fields in sudogs blocked on this channel.
	//
	// Do not change another G&#39;s status while holding this lock
	// (in particular, do not ready a G), as this can deadlock
	// with stack shrinking.
	lock mutex
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず，構造体&lt;code&gt;hchan&lt;/code&gt;のメンバーとして&lt;code&gt;lock mutex&lt;/code&gt;が見えるので，channelはgoroutine-safeです．複数のgoroutineが同時にアクセスしても問題が発生しないようになっています．goroutineがchannelに対して読み書きをしたくなったらロックを取ってから行うようになっているということです．&lt;/p&gt;

&lt;p&gt;上に示した通り，channelの実体は「circular queue（へのポインタ）」です．組み込みの&lt;code&gt;make()&lt;/code&gt;でchannelを作ると，実体はheap領域に確保され，それへのポインタが返されます．&lt;code&gt;buf&lt;/code&gt;がバッファ先頭へのポインタで，&lt;code&gt;sendx&lt;/code&gt;・&lt;code&gt;recvx&lt;/code&gt;がそれぞれキューの先頭とお尻の番号になっています．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hchan.jpeg&#34; data-caption=&#34;構造体hchan&#34;&gt;
&lt;img src=&#34;hchan.jpeg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    構造体&lt;code&gt;hchan&lt;/code&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;p&gt;なので，channelにメッセージが送り込まれたら，&lt;code&gt;buf[0]&lt;/code&gt;にメッセージが入り，&lt;code&gt;sendx&lt;/code&gt;がインクリメントされて1になります．続けてメッセージが2個送り込まれると&lt;code&gt;buf[1]&lt;/code&gt;，&lt;code&gt;buf[2]&lt;/code&gt;にメッセージが書き込まれ，&lt;code&gt;sendx&lt;/code&gt;が0に戻ります．ここでメッセージが1個読まれると&lt;code&gt;buf[0]&lt;/code&gt;の内容がdequeueて&lt;code&gt;recvx&lt;/code&gt;が1になります．特に難しいことはなく，一般のcircular queueの動作ですね．&lt;/p&gt;

&lt;p&gt;channel間のメッセージングはとても直感的に実現することができます．channelにメッセージを書き込む時は，まず&lt;code&gt;hchan&lt;/code&gt;のロックを取って，次に&lt;code&gt;buf&lt;/code&gt;のお尻に送りたいデータをメモリコピーして，アンロック．channelからメッセージを読み込む時は，同様にまず&lt;code&gt;hchan&lt;/code&gt;のロックを取って，&lt;code&gt;buf&lt;/code&gt;の先頭をメモリコピーして，アンロック．とてもシンプルな動作です．&lt;/p&gt;

&lt;p&gt;実はこの挙動こそが，golangの&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t communicate by sharing memory, share memory by communicating.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;を実装している箇所と言えます．&lt;/p&gt;

&lt;p&gt;goroutine間で共有しているのは構造体&lt;code&gt;hchan&lt;/code&gt;だけです．しかも&lt;code&gt;hchan&lt;/code&gt;はロックによって排他処理が施されるため，goroutine-safeです．&lt;code&gt;hchan&lt;/code&gt;の&lt;code&gt;buf&lt;/code&gt;に値を書き込む（つまりchannelに値を送る）・値を読み込む（つまりchannelから値を取り出す）動作は全て&lt;strong&gt;メモリコピー&lt;/strong&gt;で行われます．goroutine間でやり取りする情報は（メモリを共有するのではなくて）メモリコピーして渡しましょうというのが，上の標語の実装と言えます．&lt;/p&gt;

&lt;p&gt;channelはgoroutineの挙動をブロックしたりアンブロックしたりすることができます．バッファに空きが無いchannel（バッファ0のchannelや容量一杯データが書き込まれているchannel）に対してデータを送り込もうとすると，&lt;a href=&#34;https://github.com/golang/go/blob/1f3339f441e2053f8efd7ead417761ea319fe790/src/runtime/chan.go#L162&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;gopark()&lt;/code&gt;&lt;/a&gt;が実行されます．この関数は，golangのruntimeのスケジューラを呼び出して，バッファに空きが無いchannelにデータを送り込もうとしたgoroutineの状態を&lt;code&gt;wait&lt;/code&gt;にして別のgoroutineの実行を始めます．channelに対してデータを送り込むロジックの中に，goroutineをブロックするロジックが組み込まれているということになります．では，どうやってブロックされたgoroutineの実行を再開するのでしょうか．&lt;/p&gt;

&lt;p&gt;ここで興味深いのが，&lt;code&gt;gopark()&lt;/code&gt;の実行の直前に「どのgoroutineがどんな値を送り込もうとしていたのかをchannelの中に記録しておく」というところです．構造体&lt;code&gt;hchan&lt;/code&gt;には&lt;code&gt;sendq&lt;/code&gt;，&lt;code&gt;recvq&lt;/code&gt;というメンバがあり，そこに「このchannelにどのgoroutineがどんなデータを送り込もうとしているのか，取り出すのはどのgoroutineでどこに読み込もうとしているのか」という情報を保持しています．「このchannelにどのgoroutineがどんなデータを送り込もうとしているのか，取り出すのはどのgoroutineでどこに読み込もうとしているのか」を保持する構造体は&lt;a href=&#34;https://github.com/golang/go/blob/1f3339f441e2053f8efd7ead417761ea319fe790/src/runtime/runtime2.go#L342:6&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;sudog&lt;/code&gt;&lt;/a&gt;という名前になっています．なぜこの名前なのかは&lt;a href=&#34;https://groups.google.com/forum/#!topic/golang-codereviews/rC9BLPFvkW8&#34; target=&#34;_blank&#34;&gt;ここのメーリスの一連の流れ&lt;/a&gt;を読むとわかるかもしれませんよ．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// sudog represents a g in a wait list, such as for sending/receiving
// on a channel.
//
// sudog is necessary because the g ↔ synchronization object relation
// is many-to-many. A g can be on many wait lists, so there may be
// many sudogs for one g; and many gs may be waiting on the same
// synchronization object, so there may be many sudogs for one object.
//
// sudogs are allocated from a special pool. Use acquireSudog and
// releaseSudog to allocate and free them.
type sudog struct {
	// The following fields are protected by the hchan.lock of the
	// channel this sudog is blocking on. shrinkstack depends on
	// this for sudogs involved in channel ops.

	g *g

	// isSelect indicates g is participating in a select, so
	// g.selectDone must be CAS&#39;d to win the wake-up race.
	isSelect bool
	next     *sudog
	prev     *sudog
	elem     unsafe.Pointer // data element (may point to stack)

	// The following fields are never accessed concurrently.
	// For channels, waitlink is only accessed by g.
	// For semaphores, all fields (including the ones above)
	// are only accessed when holding a semaRoot lock.

	acquiretime int64
	releasetime int64
	ticket      uint32
	parent      *sudog // semaRoot binary tree
	waitlink    *sudog // g.waiting list or semaRoot
	waittail    *sudog // semaRoot
	c           *hchan // channel
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;gopark()&lt;/code&gt;によって受け取り手のgoroutineの実行が開始されると，&lt;strong&gt;受け取り手のgoroutineが，channelの&lt;code&gt;sendq&lt;/code&gt;の中身を確認して，実行をブロックされてしまった送り手のgoroutineが最後にchannelに送り込もうとした値を（送り手側に代わって）受け取り手側がchannelの&lt;code&gt;buf&lt;/code&gt;にコピーします&lt;/strong&gt;．これはある種の最適化です．真面目に，送り手側の実行が再開されてからchannelにデータを送り込むことにするとchannelに対するロックを取る必要があり，排他処理をする回数が1回増えてしまいます．「誰がどんな値を送ろうとしていたのか」が自明であるならば，先にやってしまえという考えのようです．&lt;/p&gt;

&lt;p&gt;channelから値を1個受け取ると，&lt;code&gt;goready()&lt;/code&gt;が実行されて，スケジューラーが起動し，バッファに空きが無いchannelにメッセージを送ろうとしたgoroutineの状態をrunnableにセットして実行待ちのキューに入ります．&lt;/p&gt;

&lt;p&gt;goroutineが空のchannelに対して読み込みを行おうとすると，そのgoroutineの動作はブロックされます．この挙動はchannelからデータを受け取るロジックである&lt;code&gt;recv()&lt;/code&gt;関数内に記述されています．さらに面白いのが，「どのgoroutineが，どこに値を受け取ろうとしていたのか」を&lt;code&gt;recvq&lt;/code&gt;に保存していることです．これによって，channelにデータを送り込むgoroutineが，受け取り先のgoroutineのスタック領域を直接いじってデータを送り切ってしまうことが可能となります．goroutineの実体は（雑に言えば）stackを持つ構造体で，OSプロセスのスタック領域に置かれています．つまり別のgoroutineの持つstackを直接いじることが，channelでのデータのやり取りの限られた状況においてのみ許されているというのが興味深いです．&lt;/p&gt;

&lt;p&gt;golangのchannel周りの実装を見て，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;「排他処理を含む簡潔な実装の方が，排他処理なしの複雑な実装よりマシ．いくらパフォーマンスが良くても，それが複雑なコードでも良いことの理由にはならない」&lt;/li&gt;
&lt;li&gt;「パフォーマンスの観点から，goroutineというユーザーレベルのスレッドを実装し（OSスレッドをブロックさせない），異なるgoroutineを跨いだメモリコピーを許す（その分実装がやや複雑になるがそれは許容する）」&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;という相反する考えが感じられます．つまり&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;simplicityとperformaceには明確なtrade-offが存在する&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ということですね．&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;今回初めてruntimeをじっくり読みました．今まで概念として理解していたものの実体をコードとして掴めたので，とても楽しかったです．今回はgoroutineとchannel周りが中心だったので，次はスケジューラー周辺をもっとつぶさに見ていきたいと思います．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang channels tutorial</title>
      <link>/post/golang-channels-tutorial/</link>
      <pubDate>Thu, 31 Oct 2019 22:32:28 +0900</pubDate>
      <guid>/post/golang-channels-tutorial/</guid>
      <description>&lt;h2 id=&#34;golangとconcurrentなプログラミング&#34;&gt;golangとconcurrentなプログラミング&lt;/h2&gt;

&lt;p&gt;「concurrentな処理をどのように実現するか」はざっくり分けて2アプローチがある．&lt;/p&gt;

&lt;p&gt;1つは「shared-memory communication」．つまり処理を実行しているworker同士は，メモリを共有して，その共有しているメモリを用いてコミュニケーションを取るというもの．この場合，データ競合が発生しないようにロックを取ったりなどの排他処理を伴うことになって，大抵の場合実装が難しくなるとされている．&lt;/p&gt;

&lt;p&gt;もう1つは「message-passing communication」．つまり処理を実行しているworker同士は，メッセージをやり取りし合うことでコミュニケーションを取るというもの．&lt;/p&gt;

&lt;p&gt;それぞれのアプローチでいろんな実装が世の中にはすでに存在していて，例えばCでconcurrentなプログラムを書こうとするとshared-memory communicationな形で書くことになる．一方でErlangは言語としてconcurrentなプログラミングをサポートしていて，Actorモデルを実装してる．&lt;/p&gt;

&lt;p&gt;golangは，設計の時点でconcurrentなプログラミングは&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Do not communicate by sharing memory; instead, share memory by communicating&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;という思想で実装することとしている．golangのconcurrentなプログラミングの実装は「&lt;a href=&#34;http://en.wikipedia.org/wiki/Communicating_sequential_processes&#34;&gt;Communicating Sequential Processes&lt;/a&gt;」と「&lt;a href=&#34;http://en.wikipedia.org/wiki/%CE%A0-calculus&#34;&gt;$\pi$-caluculus&lt;/a&gt;」を参考にしている．&lt;/p&gt;

&lt;p&gt;golangは「concurrentなプログラミングを簡潔にわかりやすく記述すること」を言語の設計レベルからサポートしているので，concurrentな処理がとても書きやすくなっている．じゃあgolangではどうやってconcurrentなプログラミングをサポートしているのかというと，concurrentなプログラミングのプリミティブとしてgoroutine，channelを提供している．&lt;/p&gt;

&lt;p&gt;「golangはconcurrentな処理が書きやすいんだよね」という話をすると混乱しがちなのが， &lt;strong&gt;「golangはconcurrentな処理を書くための道具を提供してくれるが，その実行がparallelであるかどうかはハードウェアに依存する」&lt;/strong&gt; という点．concurrentな処理は，parallelに実行することができるかもしれない（し大抵parallelに実行できるならそうしたほうがいい）が，それはハードウェアがparallelな実行をサポートしているか（例えばCPUが複数コア搭載しているか）によって決まってくる話であって，&lt;strong&gt;「プログラムがconcurrentであること」と「プログラムの実行がparallelであること」は関連はしているけれども，全く別の話．&lt;/strong&gt;Rob Pike先生も&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once. Not the same, but related. &lt;strong&gt;Concurrency is about structure, parallelism is about execution.&lt;/strong&gt; Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;って仰っている．&lt;/p&gt;

&lt;h2 id=&#34;hello-goroutine&#34;&gt;Hello, goroutine!&lt;/h2&gt;

&lt;iframe src=&#34;https://play.golang.org/p/gHKEj4ai20c&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;「golangではconcurrentなプログラムを書きやすい」ということだったので，実際にconcurrentなプログラムを書いてみると上の例みたいになる．concurrentに処理を実行するworkerは，golangの世界では&lt;code&gt;gorutine&lt;/code&gt;と呼ばれていて，&lt;code&gt;go&lt;/code&gt;という魔法の言葉に続けてworkerで実行してほしい関数を呼び出せば，それでconcurrentな処理を書き下したことになる．なんて簡単なんだ...！&lt;/p&gt;

&lt;p&gt;上の例を実行すると，&lt;code&gt;Hello! I&#39;m main&lt;/code&gt;って印字されて，もしかしたら&lt;code&gt;Hi! I&#39;m goroutine!&lt;/code&gt;も一緒に印字される &lt;strong&gt;かもしれない&lt;/strong&gt;．「かもしれない」っていうのは，goroutineは「あるgoroutineの親は自分の子供の処理が終わるのを待たない」ことになっている．この場合だと&lt;code&gt;main&lt;/code&gt;が親で&lt;code&gt;go fmt.Println(&amp;quot;Hi! I&#39;m goroutine!&amp;quot;)&lt;/code&gt;が子供の関係になっていて，&lt;code&gt;main&lt;/code&gt;の&lt;code&gt;fmt.Println(&amp;quot;Hello! I&#39;m main&amp;quot;)&lt;/code&gt;の終了したら，その時点で子供の実行も終了させられてしまう．もし，子供のgoroutineが自己紹介し終わる前に親が自己紹介しきっちゃえば子供の自己紹介は印字されないし，親の自己紹介が終わる前に子供が自己紹介しきっちゃえば，親子両方の自己紹介が聞けることになる．&lt;/p&gt;

&lt;p&gt;「なるほど．でも親が先に終わっちゃうと子供も強制終了って，それどうにかならないの？」って思った方は賢くて，どうにかするためにgoroutine間でおしゃべりできるchannelというデータ構造が実装してある．&lt;/p&gt;

&lt;h2 id=&#34;nice-to-meet-you-channel&#34;&gt;Nice to meet you, channel!&lt;/h2&gt;

&lt;p&gt;channelはgoroutineたちが同期しながらconcurrentな処理を実行していくためのmessage-passingのメカニズムを提供してくれる．channelは「そのchannelを通じてやり取りするデータの型・バッファサイズ・メッセージのやり取りの方向」で定義されて，組み込み関数の&lt;code&gt;make()&lt;/code&gt;で簡単に作ることができる．&lt;/p&gt;

&lt;p&gt;golangでは「channelはfirst-class value」として扱われる．つまりchannelは，他の値（例えばなんらかの構造体とか&lt;code&gt;int&lt;/code&gt;型の変数とか関数とか）と同じレベルで扱われる．だから関数がchannelを返すなんてこともできるし，関数の引数にchannelを与えることもできるし，channelのchannelも定義できる．&lt;/p&gt;

&lt;p&gt;channelの入出力の方向は&lt;code&gt;&amp;lt;-&lt;/code&gt;という演算子で表現することになっている．&lt;code&gt;&amp;lt;- c&lt;/code&gt;って書けばchannel &lt;code&gt;c&lt;/code&gt;からデータを読み込むことになるし，&lt;code&gt;c &amp;lt;- 1&lt;/code&gt;って書けばchannel &lt;code&gt;c&lt;/code&gt;に&lt;code&gt;1&lt;/code&gt;を書き込んだことになる．&lt;/p&gt;

&lt;p&gt;ということで，channelを使った簡単ばプログラムを書いてみるとこんな感じになる．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/id0QnvLdbFn&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;channel &lt;code&gt;done&lt;/code&gt; を使って「僕は自己紹介終わったよママ」って子供のgoroutineが親&lt;code&gt;main&lt;/code&gt;に連絡することで，実行が同期されて両方の自己紹介が聞けるようになった．&lt;/p&gt;

&lt;p&gt;channel &lt;code&gt;done&lt;/code&gt;は「&lt;code&gt;bool&lt;/code&gt;値を通す，バッファが0の，読み書きができるchannel」として定義されている．golangでは「バッファが0のchannelに対する読み書きは，情報の送受信両者がコミュニケーションの準備ができるようになるまでブロックされる」ことになっている．なので，この例だと，確実に子供goroutineの自己紹介を聞くことができることになる．「バッファが0のchannelに対する読み書きは，情報の送受信両者がコミュニケーションの準備ができるようになるまでブロックされる」という挙動から&lt;strong&gt;バッファが0のchannelは「synchronous」と言える&lt;/strong&gt;．&lt;/p&gt;

&lt;p&gt;下の例を実行すると，channel &lt;code&gt;message&lt;/code&gt;に&lt;code&gt;1&lt;/code&gt;を送り終わってから，&lt;code&gt;main&lt;/code&gt;が1秒寝てしまうので，子供はchannel &lt;code&gt;message&lt;/code&gt;に続く&lt;code&gt;2&lt;/code&gt;，&lt;code&gt;3&lt;/code&gt;を送れなくて，止められてしまう．この挙動はsynchronousということになる．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/3z4aodIMk7v&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;一方で，バッファのあるchannelに対する読み書きは「バッファが空でないなら読み込みはブロックされない」「バッファが一杯でないなら書き込みはブロックされない」という挙動になっている．なので，&lt;strong&gt;バッファのあるchannelは「asynchronous」と言える&lt;/strong&gt;．&lt;/p&gt;

&lt;p&gt;下の例を実行すると，channel &lt;code&gt;message&lt;/code&gt;はバッファを持っているので子供は&lt;code&gt;1&lt;/code&gt;，&lt;code&gt;2&lt;/code&gt;，&lt;code&gt;3&lt;/code&gt;，&lt;code&gt;4&lt;/code&gt;と（&lt;code&gt;main&lt;/code&gt;が眠りから覚める前に）立て続けに送ることができる．この挙動はまさしくasynchronousだ．&lt;/p&gt;

&lt;h2 id=&#34;oh-poor-deadlock&#34;&gt;Oh, poor deadlock...&lt;/h2&gt;

&lt;p&gt;「goroutineもchannelもわかったので」ということで下みたいなプログラムを書くと&lt;strong&gt;deadlock&lt;/strong&gt;と言われてgolangのruntimeから叱られる．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/TbJsGMyAh8r&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;これはつまりどういうことかというと，golangのruntimeが「お前のプログラム実行したけど7行目でバッファのないchannelに&lt;code&gt;42&lt;/code&gt;って送ってる（&lt;code&gt;c &amp;lt;- 42&lt;/code&gt;）けど，それしたら受信者がいないし，受信者がいないと送信者も実行を進められないので，どうすることもできなくなっちゃったぞ」と怒っているのだ．&lt;/p&gt;

&lt;p&gt;「バッファのないchannelはgoroutine間の挙動をsynchronousにするもの」なので「受信者となるgoroutineのいない，バッファ0のchannelに値を送るとdeadlockする」のだ．&lt;/p&gt;

&lt;p&gt;今回の場合だと，受信者が存在しないことが問題なので，受信者となるgoroutineを作ればうまくいく．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/czvQy77d3jU&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;lets-range-channels-and-close-them&#34;&gt;Let&#39;s &lt;code&gt;range&lt;/code&gt; channels and &lt;code&gt;close&lt;/code&gt; them.&lt;/h2&gt;

&lt;p&gt;channelは&lt;code&gt;range&lt;/code&gt;構文を使って1つずつ値を取り出すということも記述できる．でも，&lt;code&gt;range&lt;/code&gt;を使ってchannelから値を次々取り出すときは&lt;strong&gt;channelを明示的に&lt;code&gt;close()&lt;/code&gt;しないといけない&lt;/strong&gt;．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/tTmMX8Ut5gg&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;チャンネルは組み込み関数の&lt;code&gt;close()&lt;/code&gt;で「閉じる」ことができて，閉じられたchannelに対して書き込みを行おうとするとgolangのruntimeは&lt;code&gt;panic&lt;/code&gt;して，閉じられたchannelに対して読み込みを行おうとするとそのchannelの扱う型のゼロ値が得られることになっている．&lt;/p&gt;

&lt;p&gt;「閉じられたchannelに対する読み込み」の特徴は「goroutineに処理の終了を通知させる機構」として応用することができる．大抵，こういう処理終了通知を行う場合は空の構造体&lt;code&gt;struct{}&lt;/code&gt;のchannelを使う．なんてったって空の構造体は0byteだからね．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/aAV4A-7UdZj&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;あと，閉じられたchannelに対する読み込みはブロックされないので，そのまま処理は進む．&lt;/p&gt;

&lt;h2 id=&#34;multiple-channels-and-select&#34;&gt;Multiple channels and &lt;code&gt;select&lt;/code&gt;.&lt;/h2&gt;

&lt;p&gt;goroutineとchannelを使って実際になんらかの意味のあるプログラムを書こうとすると，たくさんのgoroutineとたくさんのchannelを扱うことになるのが普通である．大抵の場合「複数のchannelを同時に待ち受けたい」状況に出くわす．golangでは複数のchannelを同時に待ち受ける&lt;code&gt;select&lt;/code&gt;構文を用意している．&lt;/p&gt;

&lt;iframe src=&#34;https://play.golang.org/p/_CaWUfaJj2E&#34; width=600 height=300 frameborder=0&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;code&gt;select { case ...: ...}&lt;/code&gt;という構文で，複数のchannelを同時に待ち受け，値が書き込まれたchannelだけに対応するという，イベント駆動みたいな処理も簡単に書くことができるようになっている．&lt;/p&gt;

&lt;h2 id=&#34;channelお前最高かよ&#34;&gt;channel，お前最高かよ！&lt;/h2&gt;

&lt;p&gt;channelはマジで便利！でも使いこなすにはchannelの挙動をよく理解していないといけない．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Concurrent v.s. Parallel</title>
      <link>/post/concurrent-vs-parallel/</link>
      <pubDate>Thu, 31 Oct 2019 16:26:54 +0900</pubDate>
      <guid>/post/concurrent-vs-parallel/</guid>
      <description>

&lt;h2 id=&#34;日本語にすると&#34;&gt;日本語にすると&amp;hellip;&lt;/h2&gt;

&lt;p&gt;調べてみると，&lt;strong&gt;「Concurrentは並行」「Parallelは並列」&lt;/strong&gt;と訳されるのが一般的らしいですが，日本語にしたところで違いが判然としないので，自分なりの解釈を書いてはっきりさせておきます．&lt;/p&gt;

&lt;h2 id=&#34;っと-その前に広辞苑によれば&#34;&gt;っと，その前に広辞苑によれば&amp;hellip;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;【並行】並びゆくこと．また，並び行なわれること．「両案を並行して審議する」&lt;/p&gt;

&lt;p&gt;【並列】並び連なること．直列の対義語&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ダメだった．&lt;/p&gt;

&lt;h2 id=&#34;じゃあ-英英辞典-oxford-dictionary-で引くと&#34;&gt;じゃあ，英英辞典（Oxford Dictionary）で引くと&amp;hellip;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;concurrent&lt;/p&gt;

&lt;p&gt;Existing, happening, or done at the same time.
‘there are three concurrent art fairs around the city’&lt;/p&gt;

&lt;p&gt;parallel&lt;/p&gt;

&lt;p&gt;[Computing] Involving the simultaneous performance of operations.
‘highly parallel multiprocessor systems’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これでもダメだった．&lt;/p&gt;

&lt;h2 id=&#34;僕の理解&#34;&gt;僕の理解&lt;/h2&gt;

&lt;h3 id=&#34;concurrent&#34;&gt;Concurrent&lt;/h3&gt;

&lt;p&gt;並行とは「複数のタスクが，論理的に，同時に処理されているように見えること」&lt;/p&gt;

&lt;p&gt;具体的には，CPUが1コアの時代に，「一つのパソコンでブラウジングしながらメールが読める理由」を説明するのが「CPUがタスクをConcurrentに処理しているから」で，これが僕の「並行」の理解．&lt;/p&gt;

&lt;p&gt;細切れにたくさんの仕事をちょっとずつ進めて，全体として複数のタスクが同時に処理されているように見えるってだけで，実際に複数のタスクが同時に処理されているわけではない．&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;「一人でいろんな仕事を同時に進めている様」&lt;/strong&gt;が並行．&lt;/p&gt;

&lt;h3 id=&#34;parallel&#34;&gt;Parallel&lt;/h3&gt;

&lt;p&gt;並列とは「複数のタスクが，物理的に，同時に処理されていること」&lt;/p&gt;

&lt;p&gt;具体的にはマルチコアのプロセッサが，搭載している複数のプロセッサをちゃんと使い切って演算をしている様は，並列という言葉で形容できる．&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;「複数人が同時に，それぞれの仕事を進めている様」&lt;/strong&gt;が並列．&lt;/p&gt;

&lt;p&gt;ちなみに，「並列であれば常に並行である」という主張もあるらしい．「複数人が同時に，それぞれの仕事を進めている様」は側から見ると「いろんな仕事を同時に進めている」ように見えるから，確かにそうかもしれない．&lt;/p&gt;

&lt;h3 id=&#34;rob-pike先生によれば&#34;&gt;Rob Pike先生によれば&amp;hellip;&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Concurrency is about dealing with lots of things at once.&lt;/p&gt;

&lt;p&gt;Parallelism is about doing lots of things at once.&lt;/p&gt;

&lt;p&gt;Not the same, but related.&lt;/p&gt;

&lt;p&gt;Concurrency is about structure, parallelism is about execution.&lt;/p&gt;

&lt;p&gt;Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;なるほど&lt;/p&gt;

&lt;h3 id=&#34;結局なんだってばよ&#34;&gt;結局なんだってばよ&amp;hellip;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Concurrency is a way of structuring your program to make it easy to understand and scalable&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;and Parallelism is simply the execution of multiple goroutine in parallel&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ref&#34;&gt;ref&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://talks.golang.org/2012/waza.slide#1&#34; target=&#34;_blank&#34;&gt;Concurrency is not Parallelism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Parallelizing Sequential Graph Computations</title>
      <link>/post/parallelizing-sequential-graph-computations/</link>
      <pubDate>Tue, 29 Oct 2019 23:54:29 +0900</pubDate>
      <guid>/post/parallelizing-sequential-graph-computations/</guid>
      <description>&lt;h2 id=&#34;0-これは何&#34;&gt;0. これは何&lt;/h2&gt;

&lt;p&gt;僕が最近研究している「並行グラフ処理系」に関連して，僕自身のテーマにおいて非常に参考になった論文であるParallelizing Sequential Graph Computations&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:0&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:0&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;について，その詳細をまとめました．なお，以下の資料の内容は大学のカリキュラムの一環として行われた発表会で用いたハンドアウトです．&lt;/p&gt;

&lt;h2 id=&#34;1-背景&#34;&gt;1. 背景&lt;/h2&gt;

&lt;p&gt;一台のメモリに載り切らないほど巨大なグラフに対する計算需要の高まりを受け，グラフ計算を並列実行するPregel&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;やGraphLab&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;をはじめとする処理系が考案された．これらは「各頂点を一台の計算機と見なし，頂点ごとに処理を実行し，頂点間でコミュニケーションをとりながら状態を更新し，その収束を以って全体の解とする」ようなThink Like A Vertex(TLAV)という計算モデルを実装している．&lt;/p&gt;

&lt;p&gt;しかし，既存のグラフアルゴリズムは並列実行されることを前提としていないため，これらの処理系を利用するためには実行したいアルゴリズムをTLAVに書き下す必要があるが，これは容易な作業ではない．グラフアルゴリズムはTLAVの登場以前から研究されていて，問題を解決する最適なアルゴリズムが既に存在しているにも関わらず，TLAVな処理系ではアルゴリズムの変換が伴うため，敷居が十分に下がったとは言えない．&lt;/p&gt;

&lt;p&gt;そこで，既存のグラフアルゴリズムのロジックをそのまま用いながらも，並列実行することができるような処理系 $GRAPE$ を提案する． $GRAPE$ では，計算モデルとして，既存の分散グラフ処理系が採用するTLAVではなく，Partial evaluation &amp;amp; Incremental Computationモデル(以下$GRAPE$モデル)を採用し，既存のアルゴリズムのロジックを変更することなく並列化させる．同時に，$GRAPE$モデルはTLAVと比較してコミュニケーションコストを少なく抑えることができることからより効率的な計算の実行が可能となる．&lt;/p&gt;

&lt;h2 id=&#34;2-関連研究&#34;&gt;2. 関連研究&lt;/h2&gt;

&lt;p&gt;分散グラフ処理の計算モデルの変遷と$GRAPE$モデルの位置付けを述べる．分散グラフ処理を実現する計算モデルとして以下の二つがよく用いられる．&lt;/p&gt;

&lt;h3 id=&#34;think-like-a-vertex&#34;&gt;Think Like A Vertex&lt;/h3&gt;

&lt;p&gt;最初に提案された計算モデル．PregelやGiraph&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;，GraphLab&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;に実装されている．頂点ごとに処理を実行し，頂点間でコミュニケーションをとりながら状態を更新．全頂点の状態の収束を以って全体の解とする．&lt;/p&gt;

&lt;h3 id=&#34;think-like-a-graph-or-block-centric&#34;&gt;Think Like A Graph (or Block Centric)&lt;/h3&gt;

&lt;p&gt;TLAVを高速化しようとする研究の中で提案されたモデル．$n$個の頂点をまとめて扱うことでコミュニケーションコストを抑え，実行効率の向上を図る．Blogel&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;で実装されている．&lt;/p&gt;

&lt;p&gt;TLAVとBlock Centricモデルおよび$GRAPE$モデルを，処理単位の粒度，コミュニケーションコストの大小，プログラミングのしやすさという三つの観点から整理すると下表のようになる．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;table1.png&#34; data-caption=&#34;表1. 分散グラフ計算モデルの比較&#34;&gt;
&lt;img src=&#34;table1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    表1. 分散グラフ計算モデルの比較
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h2 id=&#34;3-partial-evaluation--incremental-computation&#34;&gt;3. Partial evaluation &amp;amp; Incremental computation&lt;/h2&gt;

&lt;p&gt;$GRAPE$では，Partial evaluation &amp;amp; Incremental computationという計算モデルを採用している．これは，最初に部分グラフに対して実行したい処理を行って部分解を求め，その部分解の更新を繰り返していくことで全体の解を求めるというモデルである．&lt;/p&gt;

&lt;h3 id=&#34;partial-evaluation&#34;&gt;Partial evaluation&lt;/h3&gt;

&lt;p&gt;コンパイラによるプログラム最適化の文脈で登場し，XML文章中の要素を指定するXPathを分散環境下で評価する研究などでも取り上げられている&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;．&lt;/p&gt;

&lt;h3 id=&#34;incremental-computation&#34;&gt;Incremental computation&lt;/h3&gt;

&lt;p&gt;巨大な動的グラフ$G$に対するクエリ$Q$の応答速度を向上させる技術．グラフの変化$\Delta G$から$Q(G \oplus \Delta G) = Q(G) \oplus \Delta O$を満たすようなクエリ出力の差分$\Delta O$を求めることで，グラフ全体を用いて再計算することなく，変化後のグラフに対するクエリ結果を求める&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:8&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:8&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;．&lt;/p&gt;

&lt;p&gt;例えば，図1のような5ノードからなるグラフ$G$を三つの部分グラフ$F_1$，$F_2$，$F_3$に分割する．部分グラフは，それを構成するノードとそのノードを始点とするエッジの終点も含めるものとして与える．例えば，部分グラフ$F_1$は図2となる．ここで，グラフ$G$に対してノード$1$を始点とする単一始点最短経路問題(SSSP)を考える．$GRAPE$ではまず，部分グラフ$F_1$に対してダイクストラ法を用いて計算する．この結果は$G$全体に対するSSSPの解ではないが，この結果は全体の解のたたき台となっている．この「部分グラフ$F_1$に対するダイクストラ法の適用」がPartial evaluationである．&lt;/p&gt;

&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;graph.png&#34; data-caption=&#34;図1. 全体グラフ&#34;&gt;
&lt;img src=&#34;graph.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    図1. 全体グラフ
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;f1.png&#34; data-caption=&#34;図2. 部分グラフ $F_1$&#34;&gt;
&lt;img src=&#34;f1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    図2. 部分グラフ $F_1$
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;$F_1$にダイクストラ法を適用することで表2を得る．ここで，ノード$4$および$5$のコストが計算されていることに注目する．これは，$F_1$のpartial evaluationの結果から，$F_3$の状態が変化した(表3におけるノード$4$および$5$の初期状態からの変化)ということであり，この変化を元に$F_3$に対してダイクストラ法を適用することで全体解に収束していく．これが，$GRAPE$のIncremental computationである．&lt;/p&gt;

&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;table2.png&#34; data-caption=&#34;表2. 部分グラフ$F_1$に対するPartial evaluation&#34;&gt;
&lt;img src=&#34;table2.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    表2. 部分グラフ$F_1$に対するPartial evaluation
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;table3.png&#34; data-caption=&#34;表3. 部分グラフ$F_3$に対するIncremental computation&#34;&gt;
&lt;img src=&#34;table3.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    表3. 部分グラフ$F_3$に対するIncremental computation
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;h2 id=&#34;4-grape&#34;&gt;4. $GRAPE$&lt;/h2&gt;

&lt;p&gt;Partial evaluation &amp;amp; Incremental computationを図3のように組み上げることで処理系$GRAPE$を実現する．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;grape.png&#34; data-caption=&#34;図3. $GRAPE$&#34;&gt;
&lt;img src=&#34;grape.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    図3. $GRAPE$
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;p&gt;$GRAPE$の利用者は実行したい処理を，$\sf PEval$(Partial evaluation相当)，$\sf IncEval$(Incremental computation)相当，部分解をまとめる$\sf Assemble$という三つのプログラムとして$GRAPE$に与える．$GRAPE$は一つの$\tt coordinator$と複数の$\tt worker$で構成され，$\tt coordinator$は部分グラフ間の接続関係やどの$\tt worker$がどの部分グラフを担当するかを管理している．$\tt worker$は各自が担当する部分グラフに$\sf PEval$や$\sf IncEval$を適用する．&lt;/p&gt;

&lt;p&gt;$GRAPE$での演算は三つのフェーズから成る．まず$\tt coordinator$がクエリの実行を受け付け，$\tt worker$が各自が担当している部分グラフに対して$\sf PEval$を実行する．次に,
各$\tt worker$が部分グラフの状態変化を$\tt coordinator$に通知する．$\tt coordinator$は部分グラフ同士の接続関係を考慮し，対応する$\tt worker$に変化を伝達する．知らせを受けた$\tt worker$は，状態変化に基づく$\sf IncEval$を実行し自分の担当している部分グラフの状態を更新する．$\sf IncEval$は更新が発生しなくなるまで繰り返される．$\sf IncEval$が収束すると，$\tt coordinator$は各$\tt worker$から部分解を回収し，最終的な出力を得る．&lt;/p&gt;

&lt;h2 id=&#34;5-grapeのアドバンテージ&#34;&gt;5. $GRAPE$のアドバンテージ&lt;/h2&gt;

&lt;p&gt;$GRAPE$は処理効率と$GRAPE$モデルの表現力において，既存の処理系に対してアドバンテージがある．$GRAPE$では部分グラフ間の状態変化をやり取りするコストのみで済むため，TLAVと比較して大幅にコミュニケーションコストが抑えられる．これによって，TLAVよりも効率的な処理が実行できる．さらに$GRAPE$で実行されるアルゴリズムのロジックは既存のものと変わらないため，既存のグラフ最適化技法を適用することができ，さらなる高速化も見込むことができる．加えて，$\sf MapReduce$など他の分散計算モデルを$GRAPE$上に表現することも可能である．例えば$\sf IncEval$でやり取りする情報を&lt;code&gt;&amp;lt;key: value&amp;gt;&lt;/code&gt;として$\sf PEval$と偶数回目の$\sf IncEval$を$\sf Map$に，奇数回目の$\sf IncEval$を$\sf Reduce$とすれば$\sf MapReduce$を表現できる．&lt;/p&gt;

&lt;h2 id=&#34;6-評価&#34;&gt;6. 評価&lt;/h2&gt;

&lt;p&gt;$GRAPE$モデルがTLAVよりも&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;処理時間&lt;/li&gt;
&lt;li&gt;コミュニケーションコスト&lt;/li&gt;
&lt;li&gt;グラフの規模に対するスケーラビリティ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の三点において，TLAVとの性能を比較し$GRAPE$モデルの優位性を検証した．プロセッサの数を64から192まで変化させながら，liveJournal&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a class=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;など複数の実世界グラフに対して単一始点最小経路問題をGiraph，GraphLab，Blogel，$GRAPE$で実行した結果を図4に示す．$GRAPE$はGiraph，GraphLab，Blogeと比べて484，36，15倍高速に処理を実行し，$\tt worker$間でやり取りされるデータ量を0.07%，0.12%，0.7%に抑えられている．&lt;/p&gt;

&lt;p&gt;グラフの規模に対するスケーラビリティを，入力グラフを5Mノード50Mエッジから25Mノード250Mエッジまで変化させながら実行時間とコミュニケーションコストを計測した．その結果を図5の左二図に示す．グラフ規模に対して十分にスケールしていることがわかる．&lt;/p&gt;

&lt;p&gt;図5の右端図から，${GRAPE}$では，並列実行に伴うオーバーヘッドを考慮してもなお，既存のアルゴリズムに対する高速化技法の効果が得られることがわかる．&lt;/p&gt;

&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;evaluation.png&#34; data-caption=&#34;表4. 処理系ごとの実行時間とコミュニケーションコスト&#34;&gt;
&lt;img src=&#34;evaluation.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    表4. 処理系ごとの実行時間とコミュニケーションコスト
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;scalability.png&#34; data-caption=&#34;表5. ${GRAPE}$のスケーラビリティーとグラフレベル最適化の効果&#34;&gt;
&lt;img src=&#34;scalability.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    表5. ${GRAPE}$のスケーラビリティーとグラフレベル最適化の効果
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;h2 id=&#34;7-結論&#34;&gt;7. 結論&lt;/h2&gt;

&lt;p&gt;Partial evaluation &amp;amp; Incremental computationという計算モデルはグラフに対しても有効であり，この計算モデルを用いることで
既存のグラフアルゴリズムのロジックをほぼ変更することなく並列化を実現でき，分散グラフ処理系を利用する敷居を下げられる．そこでPartial evaluation &amp;amp; Incremental computationを実装する処理系$GRAPE$を提案する．Partial evaluationに相当する$\sf PEval$とIncremental computationに相当する$\sf IncEval$，部分解を集める$\sf Assemble$を定義することで既存のグラフアルゴリズムの並列化を実現する．&lt;/p&gt;

&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vR18vtYd3XhDHVbLaP4DXmGELqvX_OV6s7OIdkwhNv4Wi6hLPREQ7wr1r4ki3PDX2mPhugO248Y4DG3/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:0&#34;&gt;Wenfei Fan, Wenyuan Yu, Jingbo Xu, Jingren Zhou, Xiaojian Luo, Qiang Yin, Ping Lu, Yang Cao, and Ruiqi Xu. 2018. Parallelizing Sequential Graph Computations. ACM Trans. Database Syst. 43, 4, Article 18 (December 2018), 39 pages. DOI: &lt;a href=&#34;https://doi.org/10.1145/3282488&#34;&gt;https://doi.org/10.1145/3282488&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:0&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:1&#34;&gt;Grzegorz Malewicz, Matthew H. Austern, Aart J.C Bik, JamesC. Dehnert, Ilan Horn, Naty Leiser, and Grzegorz Czajkowski.2010. Pregel: a system for large-scale graph processing. In Pro-ceedings of the 2010 ACM SIGMOD International Conferenceon Management of data (SIGMOD ’10). ACM, New York, NY,USA, 135-146.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Yucheng Low, Danny Bickson, Joseph Gonzalez, CarlosGuestrin, Aapo Kyrola, and Joseph M. Hellerstein. 2012. Dis-tributed GraphLab: a framework for machine learning and datamining in the cloud. Proc. VLDB Endow. 5, 8 (April 2012),716-727.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Giraph. &lt;a href=&#34;http://giraph.apache.org/&#34;&gt;http://giraph.apache.org/&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Yucheng Low, Danny Bickson, Joseph Gonzalez, CarlosGuestrin, Aapo Kyrola, and Joseph M. Hellerstein. 2012. Dis-tributed GraphLab: a framework for machine learning and datamining in the cloud. Proc. VLDB Endow. 5, 8 (April 2012),716-727.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Da Yan, James Cheng, Yi Lu, and Wilfred Ng. 2014. Blogel:a block-centric framework for distributed computation on real-world graphs. Proc. VLDB Endow. 7, 14 (October 2014), 1981-1992.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;Peter Buneman, Gao Cong, Wenfei Fan, and Anastasios Ke-mentsietsidis. 2006. Using partial evaluation in distributedquery evaluation. In Proceedings of the 32nd international con-ference on Very large data bases (VLDB ’06), UmeshwarDayal, Khu-Yong Whang, David Lomet, Gustavo Alonso, GuyLohman, Martin Kersten, Sang K. Cha, and Young-Kuk Kim(Eds.). VLDB Endowment 211-222
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;Wenfei Fan, Chunming Hu, and Chao Tian. 2017. Incremen-tal Graph Computations: Doable and Undoable. In Proceedingsof the 2017 ACM International Conference on Management ofData (SIGMOD ’17). ACM, New York, NY, USA, 155-169.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:8&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;Snap. &lt;a href=&#34;http://snap.stanford.edu/data/index.html&#34;&gt;http://snap.stanford.edu/data/index.html&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Emulator v.s. Simulator</title>
      <link>/post/simulator-vs-emulator/</link>
      <pubDate>Tue, 29 Oct 2019 23:24:38 +0900</pubDate>
      <guid>/post/simulator-vs-emulator/</guid>
      <description>

&lt;h2 id=&#34;ある人によれば&#34;&gt;ある人によれば&amp;hellip;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Simulation = For analysis and study&lt;/p&gt;

&lt;p&gt;Emulation = For usage as a substitute&lt;/p&gt;

&lt;p&gt;A simulator is an environment which models but an emulator is one that replicates the usage as on the original device or system.&lt;/p&gt;

&lt;p&gt;Simulator mimics the activity of something that it is simulating. It &lt;strong&gt;&amp;ldquo;appears&amp;rdquo;&lt;/strong&gt; (a lot can go with this &amp;ldquo;appears&amp;rdquo;, depending on the context) to be the same as the thing being simulated. For example the flight simulator &amp;ldquo;appears&amp;rdquo; to be a real flight to the user, although it does not transport you from one place to another.&lt;/p&gt;

&lt;p&gt;Emulator, on the other hand, &lt;strong&gt;actually &amp;ldquo;does&amp;rdquo;&lt;/strong&gt; what the thing being emulated does, and in doing so it too &amp;ldquo;appears to be doing the same thing&amp;rdquo;. An emulator may use different set of protocols for mimicking the thing being emulated, but the result/outcome is always the same as the original object. For example, EMU8086 emulates the 8086 microprocessor on your computer, which obviously is not running on 8086 (= different protocols), but the output it gives is what a real 8086 would give.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;また別の人によれば&#34;&gt;また別の人によれば&amp;hellip;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Simulator is broader than Emulator&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Simulator tends to imitate/model more global processes/things in general with ability to narrow the imitation down (e.g. capacitor simulator with presets representing some known models)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Emulator tends to imitate certain hardware devices with certain specification, known characteristics and properties (e.g. SNES emulator, Intel 8087 or Roland TB-303)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;語源を辿ると&#34;&gt;語源を辿ると&amp;hellip;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;emulate is &amp;ldquo;to be equal&amp;rdquo; (looks like more aggressive and straightforward - rivalry)&lt;/li&gt;
&lt;li&gt;simulate is &amp;ldquo;to be similar&amp;rdquo; (looks like more sly and tricky - imitation)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;日本語だと&#34;&gt;日本語だと&amp;hellip;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Emulation: （代替可能なレベルでの）模倣&lt;/li&gt;
&lt;li&gt;Simulation: 模擬&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;かな？🤔&lt;/p&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/1584617/simulator-or-emulator-what-is-the-difference&#34; target=&#34;_blank&#34;&gt;Simulator or Emulator? What is the difference?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>GitHub上でのmerge</title>
      <link>/post/three-kinds-of-merge-on-github/</link>
      <pubDate>Tue, 29 Oct 2019 19:50:58 +0900</pubDate>
      <guid>/post/three-kinds-of-merge-on-github/</guid>
      <description>

&lt;h2 id=&#34;github上でのmerge&#34;&gt;GitHub上でのmerge&lt;/h2&gt;

&lt;p&gt;GitHub上で行えるmergeには3種類あります．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create a merge commit&lt;/li&gt;
&lt;li&gt;Squash and merge&lt;/li&gt;
&lt;li&gt;Rebase and merge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらは，「merge commitの有無」「merge commitのauthorが誰になるのか」などの点で微妙に異なります．&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Command&lt;/th&gt;
&lt;th&gt;merge commitの有無&lt;/th&gt;
&lt;th&gt;merge commitのauthor&lt;/th&gt;
&lt;th&gt;merge元のbranchのcommit log&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Create a merge commit&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;merge先&lt;/td&gt;
&lt;td&gt;残る&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Squash and merge&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;merge元&lt;/td&gt;
&lt;td&gt;残らない&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Rebase and merge&lt;/td&gt;
&lt;td&gt;無&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;残る&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;create-a-merge-commit&#34;&gt;Create a merge commit&lt;/h3&gt;

&lt;p&gt;「Create a merge commit」では，&lt;code&gt;git merge --no-ff&lt;/code&gt;でmergeすることになります．つまり，merge先に新たなcommitが作成され，そのcommitがmerge元のcommitを取り込みます．このとき作成されるmerge commitのauthorはmerge先のauthorとして記録されます．&lt;/p&gt;

&lt;p&gt;この方法は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;「何をmergeしたのか」がmerge commitという形で記録として残る&lt;/li&gt;
&lt;li&gt;merge元のbranchがそのまま残るので変更箇所を追いやすい&lt;/li&gt;
&lt;li&gt;merge後に，merge元のbranchを削除したとしても，このbranchのcommit logがmerge先に残る&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;という特徴があります．わかりやすい一方で，「merge commitのauthorがmerge元ではない」のが（個人的に）「その人の頑張りを讃えたいのになぁ」とか思っちゃったりしてちょっと申し訳ない気がするとかしないとか．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;create-merge-commit.gif&#34; data-caption=&#34;Create a merge commit&#34;&gt;
&lt;img src=&#34;create-merge-commit.gif&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Create a merge commit
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h3 id=&#34;squash-and-merge&#34;&gt;Squash and merge&lt;/h3&gt;

&lt;p&gt;「Squash and merge」では，&lt;code&gt;git merge --squash&lt;/code&gt;でmergeすることになります．つまり，merge元のcommitを一つのcommitにまとめた上で，merge先にmerge commitとして先頭に追加されます．このときのmerge commitのauthorはmerge元のauthorとなります．&lt;/p&gt;

&lt;p&gt;この方法は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;「何をmergeしたのか」がmerge commitという形で記録として残る&lt;/li&gt;
&lt;li&gt;複数のcommitをまとめて一つにできるのでmerge先のcommit logがわかりやすい&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;という特徴があります．一方で，一度commitをまとめてしまうと，「どの変更が誰によってどのcommitで行われたのか」という情報が失われてしまうことになります．他の人の複数のcommitを一つのcommitに押し込むことになるので，個人的には若干怖さがあります．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;squash-and-merge.gif&#34; data-caption=&#34;Squash and merge&#34;&gt;
&lt;img src=&#34;squash-and-merge.gif&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Squash and merge
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h3 id=&#34;rebase-and-merge&#34;&gt;Rebase and merge&lt;/h3&gt;

&lt;p&gt;「Rebase and merge」では，まずmerge元のブランチにあるcommit列に対して&lt;code&gt;git rebase&lt;/code&gt;して，commit列が一列になったところでfast-forwardの形でmergeが実行されます．&lt;/p&gt;

&lt;p&gt;この方法は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mergeした結果，merge先のcommit logが一直線で見やすい&lt;/li&gt;
&lt;li&gt;merge commitが作成されない&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;という特徴があります．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;rebase-and-merge.gif&#34; data-caption=&#34;Rebase and merge&#34;&gt;
&lt;img src=&#34;rebase-and-merge.gif&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Rebase and merge
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/en/github/administering-a-repository/about-merge-methods-on-github&#34; target=&#34;_blank&#34;&gt;About merge methods on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>共通鍵暗号</title>
      <link>/post/symmetric-key-encription-scheme/</link>
      <pubDate>Mon, 28 Oct 2019 17:19:36 +0900</pubDate>
      <guid>/post/symmetric-key-encription-scheme/</guid>
      <description>

&lt;h2 id=&#34;共通鍵暗号&#34;&gt;共通鍵暗号&lt;/h2&gt;

&lt;p&gt;暗号化・復号で同一の鍵を用いる暗号化方式&lt;/p&gt;

&lt;h2 id=&#34;シナリオ&#34;&gt;シナリオ&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Aliceが秘密鍵$key$を作成し，Bobに安全に共有&lt;/li&gt;
&lt;li&gt;Aliceがメッセージ$m$を$key$で暗号化$c = Enc(m, key)$し，Bobに送信&lt;/li&gt;
&lt;li&gt;Bobが受け取った暗号文$c$を$key$で復号$m = Dec(c, key)$して平文$m$を得る&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;共通鍵暗号の満たすべき性質&#34;&gt;共通鍵暗号の満たすべき性質&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;正当性

&lt;ul&gt;
&lt;li&gt;$m = Dec(Enc(m, key), key)$が成立すること&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;秘匿性

&lt;ul&gt;
&lt;li&gt;暗号文$c$から平文$m$に関連する情報が得られないこと&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;共通鍵暗号に対する攻撃モデル&#34;&gt;共通鍵暗号に対する攻撃モデル&lt;/h2&gt;

&lt;h3 id=&#34;暗号文単独攻撃-ciphertext-only-attack&#34;&gt;暗号文単独攻撃：Ciphertext Only Attack&lt;/h3&gt;

&lt;p&gt;攻撃者が「解読対象の暗号文$c^*$」と「盗聴した暗号文$c_1$，$c_2$，$c_3$&amp;hellip;$c_k$」を手元に持っている状況での攻撃．通信路の盗聴という攻撃に相当．&lt;/p&gt;

&lt;h3 id=&#34;既知平文攻撃-known-plaintext-attack&#34;&gt;既知平文攻撃：Known Plaintext Attack&lt;/h3&gt;

&lt;p&gt;攻撃者が「解読対象の暗号文$c^*$」と「（同一の鍵で暗号化された）ランダムな平文と暗号文の対$(m_1, c_1)$，$(m_2, c_2)$，$(m_3, c_3)$&amp;hellip;$(m_k, c_k)$」を手元に持っている状況での攻撃．過去の平文が特定済みであるような状況での攻撃に相当．&lt;/p&gt;

&lt;h3 id=&#34;選択平文攻撃-chosen-plaintext-attack&#34;&gt;選択平文攻撃：Chosen Plaintext Attack&lt;/h3&gt;

&lt;p&gt;攻撃者が「解読対象の暗号文$c^*$」を持ち，「攻撃者が選んだ任意の平文に対応する暗号文を自由に入手できる」ような状況での攻撃．&lt;/p&gt;

&lt;h3 id=&#34;選択暗号文攻撃-chosen-ciphertext-attack&#34;&gt;選択暗号文攻撃：Chosen Ciphertext Attack&lt;/h3&gt;

&lt;p&gt;攻撃者が「解読対象の暗号文$c^&lt;em&gt;$」を持ち，「攻撃対象の暗号文$c^&lt;/em&gt;$を入手する前の時点で，攻撃者が自分の選んだ暗号文に対応する平文を入手することができる」ような状況での攻撃．&lt;/p&gt;

&lt;h3 id=&#34;適応的選択暗号文攻撃-adaptive-chosen-ciphertext-attack&#34;&gt;適応的選択暗号文攻撃：Adaptive Chosen Ciphertext Attack&lt;/h3&gt;

&lt;p&gt;攻撃者が「解読対象の暗号文$c^*$」を持ち，「攻撃者が選んだ任意の暗号文に対応する平文を自由に入手できる」ような状況での攻撃．&lt;/p&gt;

&lt;h2 id=&#34;鍵全数探索攻撃に対する共通鍵暗号の安全性&#34;&gt;鍵全数探索攻撃に対する共通鍵暗号の安全性&lt;/h2&gt;

&lt;p&gt;秘密鍵が$k$bitであるような共通鍵暗号では，$2^k$個の鍵を全部試せば必ず秘密鍵を得ることができる．共通鍵暗号では「鍵全数探索攻撃よりも効率的に秘密鍵を求めるアルゴリズムが存在しないこと」が安全性に対する条件である．&lt;/p&gt;

&lt;h2 id=&#34;共通鍵暗号-1&#34;&gt;共通鍵暗号&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>暗号の基礎技術</title>
      <link>/post/basic-cryptographic-technologies/</link>
      <pubDate>Mon, 28 Oct 2019 12:40:48 +0900</pubDate>
      <guid>/post/basic-cryptographic-technologies/</guid>
      <description>

&lt;h2 id=&#34;暗号の基礎技術&#34;&gt;暗号の基礎技術&lt;/h2&gt;

&lt;p&gt;暗号技術の中でも基礎となるもの．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;暗号&lt;/li&gt;
&lt;li&gt;鍵配送&lt;/li&gt;
&lt;li&gt;ハッシュ関数&lt;/li&gt;
&lt;li&gt;メッセージ認証コード&lt;/li&gt;
&lt;li&gt;デジタル署名&lt;/li&gt;
&lt;li&gt;擬似乱数生成器&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;暗号&#34;&gt;暗号&lt;/h3&gt;

&lt;p&gt;暗号とは，「正当な送信者と受信者以外に内容を秘匿する技術」のこと．送信者は平文に対して，なんらかの操作を施すことで，暗号文を生成する．この過程を暗号化という．一方で，受信者は暗号文に対してなんらかの操作を施すことで平文を得る．この過程を復号という．&lt;/p&gt;

&lt;h3 id=&#34;鍵配送&#34;&gt;鍵配送&lt;/h3&gt;

&lt;p&gt;鍵配送とは，暗号化や復号に用いる鍵を安全に配送・共有するための技術や方式のこと．鍵は「第三者に知られないように」配送する必要があります．&lt;/p&gt;

&lt;h3 id=&#34;ハッシュ関数&#34;&gt;ハッシュ関数&lt;/h3&gt;

&lt;p&gt;ハッシュ関数とは，任意長のビット列を入力として固定長のビット列を出力する関数のこと．同一の入力に対して同一の出力をする一方で，異なる入力に対して異なる出力となり，異なる入力に対して同一の出力にならないという性質が求められる．&lt;/p&gt;

&lt;h3 id=&#34;メッセージ認証コード&#34;&gt;メッセージ認証コード&lt;/h3&gt;

&lt;p&gt;メッセージ認証コードとは，「伝送路上を通ってきたデータが改ざんされていないこと」「データが期待した通信相手から送信されていること」を検証するための技術のこと．&lt;/p&gt;

&lt;h3 id=&#34;デジタル署名&#34;&gt;デジタル署名&lt;/h3&gt;

&lt;p&gt;デジタル署名とは，契約書における物理的なサインのデジタル版で，ユーザー認証とデータ認証を同時に実現する技術のこと．メッセージの改ざんを防ぎ，メッセージに対する署名は署名した本人でしか生成できないことから，後から署名者が署名した契約について否認することを防止することができる．&lt;/p&gt;

&lt;h3 id=&#34;擬似乱数生成器&#34;&gt;擬似乱数生成器&lt;/h3&gt;

&lt;p&gt;真の乱数ではないにしても，暗号論的に安全とみなせる乱数列を生成するための技術のこと．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>情報セキュリティの構成要素</title>
      <link>/post/six-elements-of-infomation-security/</link>
      <pubDate>Mon, 28 Oct 2019 11:54:27 +0900</pubDate>
      <guid>/post/six-elements-of-infomation-security/</guid>
      <description>

&lt;h2 id=&#34;情報セキュリティの構成要素&#34;&gt;情報セキュリティの構成要素&lt;/h2&gt;

&lt;p&gt;「情報セキュリティ」の言葉の指し示す意味範囲は&lt;a href=&#34;oecd.org/internet/ieconomy/15582260.pdf&#34; target=&#34;_blank&#34;&gt;OECDの情報セキュリティガイドライン&lt;/a&gt;やISO/IEC TR13335&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;として国際的に定義されている．&lt;/p&gt;

&lt;p&gt;ISO/IEC TR13335にて情報セキュリティとは下記6要素のことを指すとされている．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;機密性 Confidentiality&lt;/li&gt;
&lt;li&gt;完全性 Integrity&lt;/li&gt;
&lt;li&gt;可用性 Availability&lt;/li&gt;
&lt;li&gt;責任追跡性 Accountability&lt;/li&gt;
&lt;li&gt;真正性 Authenticity&lt;/li&gt;
&lt;li&gt;信頼性 Reliability&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;機密性-confidentiality&#34;&gt;機密性 Confidentiality&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味

&lt;ul&gt;
&lt;li&gt;意図した相手以外に情報が漏れないこと&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リスク

&lt;ul&gt;
&lt;li&gt;盗聴や内部からの情報漏洩&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対策

&lt;ul&gt;
&lt;li&gt;暗号技術&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;完全性-integrity&#34;&gt;完全性 Integrity&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味

&lt;ul&gt;
&lt;li&gt;情報が正確であること&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リスク

&lt;ul&gt;
&lt;li&gt;情報の改ざん，ノイズによるビット反転・ビットの欠落&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対策

&lt;ul&gt;
&lt;li&gt;誤り訂正符号，ハッシュ関数，メッセージ認証コード，デジタル署名&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;可用性-availability&#34;&gt;可用性 Availability&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味

&lt;ul&gt;
&lt;li&gt;ある情報にアクセスすることが許されている主体が，任意の時点で情報にアクセスすることができること&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リスク

&lt;ul&gt;
&lt;li&gt;システムへの過負荷，災害，意図しないロック&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対策

&lt;ul&gt;
&lt;li&gt;システムの多重化，クラウド化，負荷分散&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;責任追跡性-accountability&#34;&gt;責任追跡性 Accountability&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味

&lt;ul&gt;
&lt;li&gt;ユーザやシステムの振る舞いについて説明が可能であること&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リスク

&lt;ul&gt;
&lt;li&gt;ログの改ざん，否認&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対策

&lt;ul&gt;
&lt;li&gt;ロギング，デジタル署名（否認防止）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;真正性-authenticity&#34;&gt;真正性 Authenticity&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味

&lt;ul&gt;
&lt;li&gt;観測されるユーザやシステムの振る舞いが，その主体によるものであること（なりすましではない）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リスク

&lt;ul&gt;
&lt;li&gt;なりすまし&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対策

&lt;ul&gt;
&lt;li&gt;認証，デジタル署名（なりすまし防止）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;信頼性-reliability&#34;&gt;信頼性 Reliability&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味

&lt;ul&gt;
&lt;li&gt;システムが一貫して動作すること&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リスク

&lt;ul&gt;
&lt;li&gt;盗聴や内部からの情報漏洩&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対策

&lt;ul&gt;
&lt;li&gt;システムの多重化，負荷の監視&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;正確には企業のセキュリティリスクを査定する際のガイドラインを定めたものになっている．通称GMITS（Guidelines for the Management for IT Security）
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>FramworkとLibraryの違い</title>
      <link>/post/what-is-the-difference-between-library-and-framework/</link>
      <pubDate>Fri, 25 Oct 2019 22:45:15 +0900</pubDate>
      <guid>/post/what-is-the-difference-between-library-and-framework/</guid>
      <description>

&lt;h2 id=&#34;ありがちな会話&#34;&gt;ありがちな会話&lt;/h2&gt;

&lt;p&gt;「Web Application Frameworkと言ったら，やっぱりRuby on Railsだよね！」&lt;/p&gt;

&lt;p&gt;「Webのフロント開発ではjQueryってライブラリがあってだな&amp;hellip;」&lt;/p&gt;

&lt;p&gt;「最近だと，FacebookがJavascriptのフレームワークとしてReactを発表してるよね」&lt;/p&gt;

&lt;p&gt;「ReactよりAngular JSの方がいいよ」&lt;/p&gt;

&lt;p&gt;Web系の技術の話では，たくさんのFrameworkだのLibraryだのが提案されて使用されていると思います．僕なんかも初めて聞くものがあれば，すぐにググってその正体を知ろうとするのですが，どれもこれも「これは便利なWeb Frameworkです」ぐらいしか教えてくれません．Frameworkの正体って一体何なのでしょうか．気になったので調べてみました．&lt;/p&gt;

&lt;h2 id=&#34;library-v-s-framework&#34;&gt;Library v.s. Framework&lt;/h2&gt;

&lt;h3 id=&#34;library&#34;&gt;Library&lt;/h3&gt;

&lt;p&gt;Libraryは，コードの再利用を目的とした「便利な関数やクラスの（ただの）コレクション」のようなものです．Libraryに含まれる関数やクラスは，ある特定の処理を達成するロジックを含んでいて，開発者がそれらを利用することで開発を進めていくことになります．例えばグラフアルゴリズムのライブラリなら，Dijkstra法とかBellman-Ford法を実装した関数が含まれていて，開発者がその関数を利用することでアプリケーションを開発します．アプリケーションの開発者が書いているロジックにライブラリの関数が利用されるので，アプリケーションの制御は開発者側にあります．&lt;/p&gt;

&lt;p&gt;Libraryを用いることで，他の人の仕事の恩恵に与りながら開発を進めることができます．これはとても嬉しいことです．開発の速度が上がります．&lt;/p&gt;

&lt;p&gt;要するに「&lt;strong&gt;Libraryのコードを開発者が利用する&lt;/strong&gt;」のがLibraryです．&lt;/p&gt;

&lt;h3 id=&#34;framework&#34;&gt;Framework&lt;/h3&gt;

&lt;p&gt;Frameworkは， (初期化から実際の処理，終了といった) アプリケーションの制御は &lt;em&gt;全てFramework側にあります&lt;/em&gt; ．アプリケーションを開発者は，Frameworkが要求するロジックを部品としてFrameworkに提供することになるわけです．Frameworkはアプリケーションの骨格を定義しているともいるかもしれません．外枠だけ定義しているのです．このFrameworkの持つ性質は，ソフトウェア工学的には「制御の反転 IoC (Inversion of Control)」と呼ばれています．&lt;/p&gt;

&lt;p&gt;Frameworkを用いることで，アプリケーション開発者は設計についてあれやこれや悩む必要がなくなります．Frameworkの要求に従っていれば，それなりの品質のシステムが勝手に出来上がることになるからです．また，Frameworkに則ってアプリケーションを開発していくと，コードに一貫性が生まれます．これはコードに可読性を与え，メンテナンスがしやすくなります．&lt;/p&gt;

&lt;p&gt;一方で，Frameworkは「制約の集合」でもあります．アプリケーションの全体としての制御が開発者の自由にできないわけですから，Frameworkを導入するならばFrameworkの課すルールを理解する必要があります．ルールを理解するのには時間がかかるものですし，Frameworkのルールに窮屈さを感じることもあるかもしれません．小規模なその場限りの開発現場などでは，この制約がFrameworkのメリットを上回ることがあるので，Frameworkを導入しないこともあるでしょう．&lt;/p&gt;

&lt;p&gt;要するに「&lt;strong&gt;Frameworkが開発者のコードを利用する&lt;/strong&gt;」のがFrameworkです．&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;library-framework-relationship.jpeg&#34; data-caption=&#34;LibraryとFrameworkとあなた&#34;&gt;
&lt;img src=&#34;library-framework-relationship.jpeg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    LibraryとFrameworkとあなた
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.nikkeibp.co.jp/it/article/lecture/20070205/260697/&#34; target=&#34;_blank&#34;&gt;ソフトウエアのフレームワークとはなにか (日経XTECH)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/azuki8/items/ad7710fdefaedc63e3f7&#34; target=&#34;_blank&#34;&gt;フレームワークとライブラリの違い (Qiita)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.freecodecamp.org/news/the-difference-between-a-framework-and-a-library-bd133054023f/&#34; target=&#34;_blank&#34;&gt;The Difference Between a Framework and a Library (freeCodeCamp)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/148747/what-is-the-difference-between-a-framework-and-a-library&#34; target=&#34;_blank&#34;&gt;What is the difference between a framework and a library? (stackoverflow)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>🚩flagパッケージでコマンドライン引数を扱う</title>
      <link>/post/handle-commandline-args-with-flag-package/</link>
      <pubDate>Fri, 25 Oct 2019 19:04:31 +0900</pubDate>
      <guid>/post/handle-commandline-args-with-flag-package/</guid>
      <description>

&lt;h2 id=&#34;flag-パッケージ&#34;&gt;&lt;code&gt;flag&lt;/code&gt;パッケージ&lt;/h2&gt;

&lt;p&gt;Golangでは，標準パッケージとしてコマンドライン引数を扱う&lt;a href=&#34;https://golang.org/pkg/flag/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;flag&lt;/code&gt;&lt;/a&gt;パッケージが付属しています．「痒い所に手が届く」とはこのことですね．&lt;/p&gt;

&lt;h2 id=&#34;フラグの立っていないコマンドライン引数の取得&#34;&gt;フラグの立っていないコマンドライン引数の取得&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Parse()&lt;/code&gt;の後に&lt;code&gt;Args()&lt;/code&gt;で&lt;code&gt;[]string&lt;/code&gt;として取得できます．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
	&amp;quot;flag&amp;quot;
	&amp;quot;fmt&amp;quot;
)

func main() {
	flag.Parse()
	args := flag.Args()
	fmt.Println(args)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run with-no-flag0.go a b c
[a b c]
$ go run with-no-flag0.go 1 2 3
[1 2 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$n$番目の要素のみを取り出したい場合は&lt;code&gt;Arg(n)&lt;/code&gt;で&lt;code&gt;string&lt;/code&gt;として取得できます．$n$番目の要素が存在しない場合は&lt;code&gt;&amp;quot;&amp;quot;&lt;/code&gt;が返ってくるようです．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
	&amp;quot;flag&amp;quot;
	&amp;quot;fmt&amp;quot;
)

func main() {
	flag.Parse()
	fmt.Println(flag.Arg(0), flag.Arg(1))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run with-no-flag1.go hoge fuga
hoge fuga
$ go run with-no-flag1.go 1
1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;フラグの立っているコマンドライン引数の取得&#34;&gt;フラグの立っているコマンドライン引数の取得&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;型名()&lt;/code&gt;もしくは&lt;code&gt;型名Var()&lt;/code&gt;で，フラグを定義したのち，&lt;code&gt;Parse()&lt;/code&gt;でそれぞれの変数を取得できます．&lt;/p&gt;

&lt;p&gt;フラグの定義は「フラグ名」「デフォルト値」「ヘルプメッセージ」で行います．&lt;/p&gt;

&lt;p&gt;&lt;code&gt;型名()&lt;/code&gt;の場合は，指定した型へのポインタが返ってきます．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
	&amp;quot;flag&amp;quot;
	&amp;quot;fmt&amp;quot;
)

func main() {
	var (
		i = flag.Int(&amp;quot;int&amp;quot;, 0, &amp;quot;int flag&amp;quot;)
		s = flag.String(&amp;quot;str&amp;quot;, &amp;quot;default&amp;quot;, &amp;quot;string flag&amp;quot;)
		b = flag.Bool(&amp;quot;bool&amp;quot;, false, &amp;quot;bool flag&amp;quot;)
	)
	flag.Parse()
	fmt.Println(*i, *s, *b)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run with-flag0.go -int 2 -str hello -bool true
2 hello true
$ go run with-flag0.go
0 default false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;型名Var()&lt;/code&gt;の場合は，引数で渡した変数に代入されます．また，適切な値を渡さないと怒られます．ダメな理由も教えてくれるので怒られがいがあります．定義していないフラグも受け付けてくれません．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
	&amp;quot;flag&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;time&amp;quot;
)

func main() {
	var (
		d time.Duration
		f float64
	)
	flag.DurationVar(&amp;amp;d, &amp;quot;dur&amp;quot;, 1 * time.Second, &amp;quot;duration flag&amp;quot;)
	flag.Float64Var(&amp;amp;f, &amp;quot;float&amp;quot;, 0.1, &amp;quot;float flag&amp;quot;)
	flag.Parse()
	fmt.Println(d, f)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run with-flag1.go -dur 1h -float 2.3
1h0m0s 2.3
$ go run with-flag1.go -float str
invalid value &amp;quot;str&amp;quot; for flag -float: strconv.ParseFloat: parsing &amp;quot;str&amp;quot;: invalid syntax
Usage of /var/folders/.../with-flag1:
  -dur duration
    	duration flag (default 1s)
  -float float
    	float flag (default 0.1)
exit status 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;フラグの書き方&#34;&gt;フラグの書き方&lt;/h2&gt;

&lt;p&gt;フラグの書き方は次の2通りが可能です．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-flag value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-flag=value&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ただし，Bool値を取得する場合は&lt;code&gt;flag=value&lt;/code&gt;を使った方がいいかもしれません．というのも， &lt;strong&gt;フラグの型がBool値かつ引数が続かない場合，フラグが立っただけで&lt;code&gt;true&lt;/code&gt;となる&lt;/strong&gt;からです．&lt;/p&gt;

&lt;p&gt;つまり，フラグを立ててBool値を取得したい場合は&lt;code&gt;-bool=true&lt;/code&gt;/&lt;code&gt;-bool=false&lt;/code&gt;としなければならないということです．&lt;code&gt;-bool false&lt;/code&gt;では&lt;code&gt;true&lt;/code&gt;となってしまいます．また&lt;code&gt;-bool false&lt;/code&gt;以降の引数が全てフラグ無しで渡された引数として評価されてしまいます．注意が必要ですね．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
	&amp;quot;flag&amp;quot;
	&amp;quot;fmt&amp;quot;
)

func main() {
	var (
		i = flag.Int(&amp;quot;int&amp;quot;, 0, &amp;quot;int flag&amp;quot;)
		s = flag.String(&amp;quot;str&amp;quot;, &amp;quot;default&amp;quot;, &amp;quot;string flag&amp;quot;)
		b = flag.Bool(&amp;quot;bool&amp;quot;, false, &amp;quot;bool flag&amp;quot;)
	)
	flag.Parse()
	fmt.Println(*i, *s, *b)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run with-flag0.go -bool false -int 123 -str abc # falseを含むそれ以降が全て非フラグで渡されたコマンドライン引数として扱われる
0 default true 
$ go run with-flag0.go -bool=true -int 123 -str abc
123 abc true
$ go run with-flag0.go -bool=false -int 123 -str abc
123 abc false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに&lt;code&gt;-h&lt;/code&gt;でヘルプを表示してくれます．賢いですね．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run with-flag0.go -h
Usage of /var/folders/.../with-flag0:
  -bool
    	bool flag
  -int int
    	int flag
  -str string
    	string flag (default &amp;quot;default&amp;quot;)
exit status 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コマンドライン引数の個数を数える&#34;&gt;コマンドライン引数の個数を数える&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;NArg()&lt;/code&gt;で非フラグなものを，&lt;code&gt;NFlag()&lt;/code&gt;でフラグなものをカウントできます．&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
	&amp;quot;flag&amp;quot;
	&amp;quot;fmt&amp;quot;
)

func main() {
	flag.Int(&amp;quot;int&amp;quot;, 0, &amp;quot;int flag&amp;quot;)
	flag.String(&amp;quot;str&amp;quot;, &amp;quot;default&amp;quot;, &amp;quot;string flag&amp;quot;)
	flag.Bool(&amp;quot;bool&amp;quot;, false, &amp;quot;bool flag&amp;quot;)
	flag.Parse()
	fmt.Println(&amp;quot;non flag:&amp;quot;, flag.NArg())
	fmt.Println(&amp;quot;flag:&amp;quot;, flag.NFlag())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go run flag-test.go -int 1 -str foo -bool=true a b
non flag: 2
flag: 3
$ go run flag-test.go -int 1 -str foo -bool true a b
non flag: 3
flag: 3
$ go run flag-test.go -bool true -int 1 -str foo a b
non flag: 7
flag: 1
$ go run flag-test.go a b c -bool=true -str foo
non flag: 6
flag: 0
$ go run flag-test.go -bool=true -str foo a b c
non flag: 3
flag: 2
$ go run flag-test.go a b c
non flag: 3
flag: 0
$ go run flag-test.go -bool=true -str foo
non flag: 0
flag: 2
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>HugoとGitHub Pagesでブログを作ってみた！</title>
      <link>/post/about-this-site/</link>
      <pubDate>Fri, 25 Oct 2019 17:21:38 +0900</pubDate>
      <guid>/post/about-this-site/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;最近はもっぱら卒論の実装ばかりやっています，zakです．&lt;/p&gt;

&lt;p&gt;プログラム書くのって難しいですよね．僕にとってはとても難しいので，わからないことがあったらデキる人のブログを参考にさせていただいたりしています．
そんな中で，自分もコードを書くことが増えてきて，そこで得た知識をなんらかの形で発信できないかなと思って，このブログを思いつきで始めました．&lt;/p&gt;

&lt;h2 id=&#34;採用技術&#34;&gt;採用技術&lt;/h2&gt;

&lt;p&gt;このブログはサイトジェネレータとしてHugo，ホスティングサービスとしてGitHub Pagesを採用しています．&lt;/p&gt;

&lt;p&gt;HugoはGolangで記述されたオープンソースの静的サイトジェネレーターです．設定をtomlで書いて，記事をMarkdownで書いて，それをHugoがHTMLその他ファイルに爆速でしたためてくれます．真面目にウェブサイトを作ろうとすると，「書きにくいHTMLで文章を書いて，CSSで見栄えを整えて」という感じで作っていくことになります．HTMLってあんまり洗練されていなくて人間にとっては読みずらいですよね．一方でMarkdownは文法が簡単なので，箇条書きでメモってるぐらいの感覚で構造を持った文章が書けてしまいます．Hugoを使うことで，サイト作成者はMarkdownというわかりやすい文法で記事を書くことができ，本来の仕事に専念できるわけです．&lt;/p&gt;

&lt;p&gt;Hugoのいいところはそれだけではありません．Hugoはその便利さから，多くのユーザーから愛されていて，そのユーザーらがそれぞれ美しいデザインテーマを公開してくれています．どれもセンスが良く，機能面でも充実しています．このテーマはオープンソースで公開されているので，カスタマイズも簡単です．そこらへんのブログサービスを利用すると，テーマがどれも陳腐で不満ですよね．&lt;/p&gt;

&lt;p&gt;今回はMarkdownで記事が執筆できるところとHugoで用いることができるAcademicというテーマが気に入ったので，Hugoを使うことにしました．&lt;/p&gt;

&lt;p&gt;GitHub Pagesは，GitHubが提供している静的サイトのホスティングサービスです．GitHubのアカウントさえあれば，誰でも静的なサイトを公開することができます．何より無料なので，これを使わない手はありません．サイトのソースコードをGitHubで管理しつつ公開もできちゃうなんて，GitHubは太っ腹ですね．&lt;/p&gt;

&lt;p&gt;GitHub Pagesの他にもホスティングサービスはありますが，ソースコード管理と一緒にホスティングできるところが便利だと思ったので採用しました．&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;気が向いたら，もうちょっと追記します 🙇&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>🚀最初の投稿</title>
      <link>/post/first-post/</link>
      <pubDate>Fri, 25 Oct 2019 17:07:09 +0900</pubDate>
      <guid>/post/first-post/</guid>
      <description>

&lt;h1 id=&#34;ご挨拶&#34;&gt;ご挨拶&lt;/h1&gt;

&lt;p&gt;はじめまして．技術ブログ始めてみました．ぼちぼち投稿します 👍&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
