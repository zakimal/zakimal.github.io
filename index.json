[{"authors":["admin"],"categories":null,"content":"はじめまして！zak です．\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"ja","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"はじめまして！zak です．","tags":null,"title":"尾崎 耀一 (@zak)","type":"authors"},{"authors":[],"categories":[],"content":" データのserialization/deserialization イマドキのソフトウェアは，機能ごとにプログラムを整理整頓して，それらが情報をやりとりしながらサービスを提供します．システムを構成するコンポーネント間でメッセージングをしなければならず，その際にやりとりするデータについて「どういう表現であるのか」について共有しておかないといけません．人間の会話で言うならば「何語を喋るか」に近いのかな．\n「どんな形式でデータを表現するか」についてはいくつかの形式が提案されていて，それぞれについて一長一短がある．代表的なのはXML，JSON，BSON，Protocol Buffers，FlatBuffers．他にもいろいろあります．\nXML XMLとは「eXtended Markdown Language」の略で，文章の電子化に源流があるデータ形式．前提に「文章のデジタル化」があるので，XMLの仕様にはデータの「型」が定義されていません．\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;breakfast_menu\u0026gt; \u0026lt;food\u0026gt; \u0026lt;name\u0026gt;Belgian Waffles\u0026lt;/name\u0026gt; \u0026lt;price\u0026gt;$5.95\u0026lt;/price\u0026gt; \u0026lt;description\u0026gt; Two of our famous Belgian Waffles with plenty of real maple syrup \u0026lt;/description\u0026gt; \u0026lt;calories\u0026gt;650\u0026lt;/calories\u0026gt; \u0026lt;/food\u0026gt; \u0026lt;food\u0026gt; \u0026lt;name\u0026gt;Strawberry Belgian Waffles\u0026lt;/name\u0026gt; \u0026lt;price\u0026gt;$7.95\u0026lt;/price\u0026gt; \u0026lt;description\u0026gt; Light Belgian waffles covered with strawberries and whipped cream \u0026lt;/description\u0026gt; \u0026lt;calories\u0026gt;900\u0026lt;/calories\u0026gt; \u0026lt;/food\u0026gt; \u0026lt;/breakfast_menu\u0026gt;  XMLは文章のデジタル化が前提にあるので，HTMLみたいな見た目になっています．\nXMLの特徴として「XMLはself-describingである」と評されることが多くあります．これは「データ自体の構造がデータそのものに表現されている」ということです．つまり事前に通信の両端でやり取りするデータの方についての合意をとっていなくても（やり取りするデータを眺めれば）データの齟齬のない解釈が可能であるということです．JSONだとこれはできません．XMLはタグだけをみることで，そのデータの構造を即座に読み取ることができます．JSONでは，タグに相当するものをハッシュのキーとして表現すればできないわけではないが，それはデータの型を表現したわけではなくて，ハッシュを用いて似たようなデータ型を表現しただけです．\nXMLで記述されたデータはそれ自身のメタな構造をも表現しているという点が分散システムにおけるデータのやり取りで非常に有用なので，古くからよく使われています．\nJSON JSONとは「JavaScript Object Notation」の略．JSONをシステム間のデータの表現形式として用いると「JavaScriptでのデータのリテラルな表現をそのままシステム間のデータ表現形式」として用いることになって，webな世界だとJavaScriptのインタプリタでそのまま処理できるので扱いやすくてよく用いられがち．しかも，JSONは人間にとってもパッと見でデータの構造が把握しやすくて人気が出ました．それなりに古参なデータ形式ですが，現在もバリバリの現役です．視認性が良いのがやっぱり人気の理由なんですかね．デバッグしやすいし．\nJSONは「プログラミング言語におけるデータのリテラル表現」が出所なので，仕様として「型」が含まれていて，扱いやすいです．「型」が仕様として存在しているので「空の値」を型ごとに区別することができます．\n{ \u0026quot;null\u0026quot;: null, \u0026quot;string\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;array\u0026quot;: [], \u0026quot;dict\u0026quot;: {} }  JSONは，こんなにシステム間で情報をやりとりする際のデータ形式として用いられるようになることを全然想定していなかったので，扱いづらさがあったりするらしい．僕は具体的に表現することができないが「古臭い」なんて言われることもあります．\n「どういうフィールドを持ったJSONデータを扱うのか」について通信の両端点で合意しておく必要があるのはもちろんですが，JSONのデータ形式はスキーマを直接的に表現しているわけではない（つまりインタフェースをJSONが規定しているわけではない）という認識も大事だと思います．そのままのJSONはただのデータ形式に過ぎなくて，スキーマ言語としての「データ型を定義する」というメタな機能はないということです．\nJSONなどでも「JSONでJSONのスキーマを書いてしまおう」というJSON Schemaなるものが存在しているそうですが，やっぱりだいぶ書きにくそうです．\n{ \u0026quot;productId\u0026quot;: 1, \u0026quot;productName\u0026quot;: \u0026quot;An ice sculpture\u0026quot;, \u0026quot;price\u0026quot;: 12.50, \u0026quot;tags\u0026quot;: [ \u0026quot;cold\u0026quot;, \u0026quot;ice\u0026quot; ], \u0026quot;dimensions\u0026quot;: { \u0026quot;length\u0026quot;: 7.0, \u0026quot;width\u0026quot;: 12.0, \u0026quot;height\u0026quot;: 9.5 }, \u0026quot;warehouseLocation\u0026quot;: { \u0026quot;latitude\u0026quot;: -78.75, \u0026quot;longitude\u0026quot;: 20.4 } }  というスキーマをJSONで書くと\n{ \u0026quot;$schema\u0026quot;: \u0026quot;http://json-schema.org/draft-07/schema#\u0026quot;, \u0026quot;$id\u0026quot;: \u0026quot;http://example.com/product.schema.json\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;Product\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;A product from Acme's catalog\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;, \u0026quot;properties\u0026quot;: { \u0026quot;productId\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;The unique identifier for a product\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;productName\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;Name of the product\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, \u0026quot;price\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;The price of the product\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;number\u0026quot;, \u0026quot;exclusiveMinimum\u0026quot;: 0 }, \u0026quot;tags\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;Tags for the product\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;array\u0026quot;, \u0026quot;items\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, \u0026quot;minItems\u0026quot;: 1, \u0026quot;uniqueItems\u0026quot;: true }, \u0026quot;dimensions\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;, \u0026quot;properties\u0026quot;: { \u0026quot;length\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;number\u0026quot; }, \u0026quot;width\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;number\u0026quot; }, \u0026quot;height\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;number\u0026quot; } }, \u0026quot;required\u0026quot;: [ \u0026quot;length\u0026quot;, \u0026quot;width\u0026quot;, \u0026quot;height\u0026quot; ] }, \u0026quot;warehouseLocation\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;Coordinates of the warehouse where the product is located.\u0026quot;, \u0026quot;$ref\u0026quot;: \u0026quot;https://example.com/geographical-location.schema.json\u0026quot; } }, \u0026quot;required\u0026quot;: [ \u0026quot;productId\u0026quot;, \u0026quot;productName\u0026quot;, \u0026quot;price\u0026quot; ] }  🤔 ﾁｮｯﾄﾐﾆｸｲ\u0026hellip;\nBSON JSONはテキストベース（つまりシリアライズ・デシリアライズの際に扱われるデータの単位がbitじゃなくてbyte）でしたが，それを改めたBSON = Binary JSONというのも存在します．つまりBSONではデータがバイナリベース（つまりシリアライズ・デシリアライズの際に扱われるデータの大きさの単位がbit）になっています．BSONは後述するProtocol Buffersとよく似ていて，度々比較されています．公式によると，\n Lightweight\n Keep­ing spa­tial over­head to a min­im­um is im­port­ant for any data rep­res­ent­a­tion format, es­pe­cially when used over the net­work.  Traversable\n BSON is de­signed to be tra­versed eas­ily. This is a vi­tal prop­erty in its role as the primary data rep­res­ent­a­tion for Mon­goDB.  Efficient\n En­cod­ing data to BSON and de­cod­ing from BSON can be per­formed very quickly in most lan­guages due to the use of C data types.   という特徴があります．\nBSONは，Protocol Buffersと比較して\n more \u0026ldquo;schema-less\u0026rdquo;\n であるとされています．つまり，サービス間のインタフェースの仕様そのものとやりとりするデータ形式の関係性が（Protocol Buffersと比較して）疎で，より柔軟性があるということです．一方で，BSONはProtocol Buffersと比べてメッセージのフィールド名のエンコードに関してやや冗長であるとされています．\nMongoDBがBSONをデータの表現方式として採用しているのが興味深いですね．多くの主要言語でBSONのエンコード・デコードをサポートするライブラリが実装されていて手軽に使えそうな印象です．ただ，バイナリベースということもあって，BSONをそのまま眺めても人間には意味がわからないので，デバッグはちょっと大変なのかもしれませんね．\n例えば{\u0026quot;hello\u0026quot;: \u0026quot;world\u0026quot;}をBSONでエンコードすると以下のようになります．\n \\x16\\x00\\x00\\x00 // total document size \\x02 // 0x02 = type String hello\\x00 // field name \\x06\\x00\\x00\\x00world\\x00 // field value \\x00 // 0x00 = type EOO ('end of object')  Protocol Buffers Protocol BuffersはGoogleが社内のシステム間で情報をやりとりする際に用いていたデータ形式で2008年にオープンソース化されました．Googleが出している公式のドキュメントによれば\n Protocol buffers are a flexible, efficient, automated mechanism for serializing structured data – think XML, but smaller, faster, and simpler.\n ということらしいです．Protocol Buffersはシステム間で情報をやりとりする際に用いるデータ形式の一種なんですが，それは嘘じゃないんですけど，Protocol Buffersの指す意味範囲はそれだけにとどまらず，サービス間のインタフェースを定義するスキーマ言語としての顔もあるのが特徴です．もっというと，このスキーマ言語が優秀であるというのがProtocol Buffersの人気を大きく支えている理由なのだと思います．「Protocol Buffersがスキーマ言語である」というのはどういうことかというと，Protocol Buffersでは「システムのインタフェース（つまり，どんな型のデータをやりとりするのか）を定義する独自言語」であるということです．\nsyntax = \u0026quot;proto3\u0026quot;; package example.protobuf; message SimpleMessage { message HeaderItem { string name = 1; string value = 2; } enum Type { START = 0; BLOB = 1; END = 2; } uint64 id = 1; Type message_type = 2; repeated HeaderItem headers = 3; bytes blob = 4; }  Protocol Buffersは，サービス間でやりとりするデータの型を表現する独自言語とともに，その独自言語で記述されたインタフェースを特定の言語にコンパイルするツールまでもが同梱されています．\nスキーマ言語が存在すると，非常に便利です．モダンなソフトウェアシステムでは，いろんなところにデータが保存されているかもしれないし，バックエンドで動いているサーバーもいくつかあるかもしれないし，もはやそれが普通になってきています．となると，システムの中のありとあらゆる場所でデータのシリアライズ・デシリアライズをしなければならないし，通信している両者でデータの解釈に矛盾が発生しないように整える必要があります．スキーマ言語があると，この「整える作業」がとてもやりやすくなります．自然言語と違って，スキーマ言語では解釈に差異が発生しないからです．「管理者が一人」みたいなシステムでは，スキーマ言語なんてたいそうなものを持ち出してくる必要はないと思うんですけど，webみたいな自律分散的な系だと，ますますスキーマ言語としてのProtocol Buffersの良さが際立ってくるわけです．\nProtocol Buffersのスキーマ言語としての良さは，その簡潔さではないでしょうか．プログラムを書く人間にとっては，特に難しいことを考えずに意図が汲み取れる程度の決まりごとしかないし，スキーマ言語としてプログラミング言語から独立している点も，ツールの作りやすさとかに影響していて，Protocol Buffersが人気な理由なんだと思います．\nProtocol Buffersでは，.protoファイルとしてサービスインタフェースを記述します．\nmessage Person { required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { required string number = 1; optional PhoneType type = 2 [default = HOME]; } repeated PhoneNumber phone = 4; }  明確なサービスインタフェースをコンパイラによって適切に所望の言語のプログラムに変換してくれるので，開発を進めやすくなります．\nProtocol Buffersではサービスのインタフェースの変更に対して後方互換性を維持した形でメッセージのやり取りをできるように「未知なフィールドに遭遇したら無視する」ということになっています．こうすれば，サービスのインタフェースが更新されたとしても，既存のプログラムは動くことには動くことになります．\nProtocol Buffersの公式のドキュメントでは，XMLと比較して\n Protocol buffers\n are simpler are 3 to 10 times smaller are 20 to 100 times faster are less ambiguous generate data access classes that are easier to use programmatically   と主張しています．確かにXMLはいちいちタグで括らなきゃいけないしProtocol Buffersは効率が良さそうです．\nProtocol Buffersのデフォルトのシリアライズはバイナリベースです．人間が眺めて構造が取れるような見た目にはなっていません．しかしProtocol Buffersはシリアライズのフォーマットとして様々な形式（例えばJSONなど）も扱えるように周辺ツールが充実しているので，「スキーマ言語としてのProtocol Buffersでサービスのインフェースを記述して，実際にやり取りするデータはJSON」ということも可能になっています．\nFlat Buffers これもGoogleによってオープンソース化されたデータのシリアライズ・デシリアライズ方式．公式によれば，\n  Access to serialized data without parsing/unpacking Memory efficiency and speed Flexible Tiny code footprint Strongly typed Convenient to use Cross platform code with no dependencies   という特徴があります．面白いのが「Access to serialized data without parsing/unpacking」ってところですね．FlatBuffersでは階層構造を持つデータを，パースすることなく直接扱うことができるらしいです．\nProtocol Buffersの進化系として自らを位置づけていて，Flat Buffersではデータをパースする必要がないのでProtocol Buffersと比較してコード量が桁違いで削減できて，さらにFlat BuffersではProtocol Buffersより強力に型をサポートしているところが進化ポイントですね．white paperのmotivationの章には\n In particular, FlatBuffers focus is on mobile hardware (where memory size and memory bandwidth is even more constrained than on desktop hardware), and applications that have the highest performance needs: games.\n とあり，シリアライズの効率について高水準なものが求められる状況で用いられることが想定されているそうです．\nFacebookで用いられているらしいですが，Protocol Buffersの人気に押されて，あまり流行っている感じはしないんですがどうなんでしょうか．\nRef XML  hoge hoge  JSON  What is JSON - W3Schools JSON Introduction - W3Schools JSON Schema  BSON  BSON  Protocol Buffers  Protocol Buffers  Flat Buffers  Flat Buffers  ","date":1572796985,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572796985,"objectID":"5151db0bcc6ba8833835903e97cc00dd","permalink":"/post/json-vs-protobuf-vs-flatbuf/","publishdate":"2019-11-04T01:03:05+09:00","relpermalink":"/post/json-vs-protobuf-vs-flatbuf/","section":"post","summary":"聞いたことのあるシリアライゼーション形式について調べてみました","tags":["XML","JSON","ProtoBuf","FlatBuf","Data Serializing"],"title":"Data Serializationのさまざま","type":"post"},{"authors":[],"categories":[],"content":" 並行処理？並列処理？ 並行処理とか並列処理って一体なんなのでしょう．\n黎明期の計算機では，並行処理だの並列処理だのなんてことは，一切考えていませんでした．入力された命令を1つずつ，真面目に実行していくことで計算を実行していたのです．黎明期の計算機は，人間が紙と鉛筆でちんたら計算をするよりも，何倍も高速にかつ正確に計算をすることができたので，とても人気になりました．ただ，その当時の計算機は物理的にサイズもデカくて高価なものでした．なので，計算機を導入・設置できるのは大学などのお金と部屋が余っている組織ぐらいしかなかったわけです．\n大学に計算機が設置されると，大学の研究者たちは喜びました．これで面倒な手計算から解放されるわけですからそりゃそうでしょう．みんなでこぞって計算機を使いたくなります．でも「計算機を利用したい研究者の人数」が「設置してある計算機の台数」と比較して圧倒的に多いので，計算機の使用を巡って争奪戦が起こります．だって，当時の計算機は「入力された命令を1つずつ，真面目に実行していく」タイプの計算機なので，他の誰かが計算機に計算をさせている間は，他の研究者はその計算機を使うことができないからです．そんなの不便すぎます．せっかく便利でしかもめちゃんこ高価な計算機が設置してあるのに，しかも使いたい人はたくさんいるのに使わせてあげられないなんて，もう不満タラタラです．そこで研究者たちは考えました．\n「どうやって1台の計算機を複数人で共有して使うことができるだろうか？」\n「1台の計算機で複数のタスクを処理するためにはどんな仕組みが必要なんだろうか？」\nここからoperating systemとかprocessとかいろんな概念が確立されていくわけです．\n「並行」というのは，英語ではconcurrentに相当し，「1台のマシンで複数のタスクを同時に実行している（ように見える）様」を意味します．concurrentな処理は「限られたリソースを有効活用すること」を目的としていて，現在の計算機では「同時に処理しているように見せるために，複数のタスクを時間的に細切れにして全部のタスクをちょっとずつ進める」ことでconcurrentな処理を実現しています．\n一方で，似たような概念として「並列」というものもあります．英語ではparallelに相当し，「複数台のマシンで1つのタスクを実行している様」を意味します．parallelな処理は「（複数のマシンという）豊富なリソースを利用して1つのタスクを高速に実行すること」を目的としていて，concurrentとは目的が違います．\nconcurrentなプログラム ここまで計算機の進化の歴史を本当にざっくり見てみましたが，じゃあconcurrentという概念がプログラムとどう絡んでいくのでしょうか．\nプログラムというのは大体「CPUでの演算」「データのI/O」「ネットワーキング」を部品として構成されています．それぞれの部品には特徴があって，「CPUでの演算」はとても高速に実行できるけれども，「データのI/O」と「ネットーワーキング」は（「CPUでの演算」と比較して）桁違いに，本当に桁違いに時間がかかります．もし計算機が「入力された命令を1つずつ，真面目に実行していく」方式で動いていたとすると，「データのI/O」と「ネットーワーキング」に取り組んでいる間，計算機はうんともすんとも言わずに黙り込んでしまうことになります．これは明らかに無駄です．CPUは何も計算を進めないでただ存在しているだけになるわけです．\nconcurrentという概念の背景には「どうやって1台の計算機を複数人で共有して使うことができるだろうか？」という問題があったわけです．この問題意識が一歩進むと，「1台の計算機で複数のタスクを処理するためにはどんな仕組みが必要なんだろうか？」となり，さらに一歩進んで「（複数のタスクで構成される）1つのプログラムを1台のCPUで効率的に処理するためにはどういう仕組みが必要なんだろう？\u0026hellip;そうだ！CPUが暇な時間帯には別の仕事をさせよう！」となるわけです．\n「時間がかかってしまう処理をやっている間に，他にできる計算をCPUにやらせよう」というのがconcurrentなプログラムを書きたい理由です．だってそうした方がやりたいこと早く終わるでしょう．しかもPersonalな計算機が世の中に普及して「計算機はより高速にユーザーの動作に応答しなきゃいけない（うんともすんとも言わない計算機は嫌われてる）」し「ユーザーは大抵の場合音楽聴きながらメールチェックしつつYoutubeで動画も見たいワガママな存在」なので，CPUに暇な時間なんてものはないわけですよ．\n「プログラムはconcurrentに実行されるべき」となるとconcurrentなプログラムを記述して，それを実際にconcurrentに実行する機構が必要になります．\n「実際にconcurrentに実行する機構」についてはOperating Systemが頑張って，プログラムがconcurrentに実行されるように実行環境を提供します．Operating Systemは結構頑張るのですが，やっぱり頑固なハードウェアさんとやりとりしないといけないので，相当大変そうです．提供してくれる実行環境の効率にも限度がありそうです．\n「concurrentなプログラムを記述」するところについては，プログラミング言語の守備範囲なわけですが，いろんな言語がいろんなアプローチを取って，concurrentなプログラムをより簡単に書けるように，プログラム開発者に部品primitiveを提供してくれます．\nでも古参のプログラミング言語たちは，そのデザインの根幹に「プログラムがconcurrentに実行される」とか想定していないわけで，いざやろうとすると不自然なところとかがやっぱりでてきてしまいます．なのでgolangは，言語のデザインの段階でconcurrencyを考慮した言語として誕生しました．そうすれば，concurrentなプログラムがより直感的にわかりやすく書けるようになるわけです．\ngoroutineとchannel golangはconcurrentなプログラムを書くためのprimitiveとしてgoroutineとchannelを提供しています．というのもgolangでは，concurrentなプログラムを「goroutineたちがメッセージをやりとりしながら進行する計算」としてモデル化しているのです．ここで注意しておきたいのが，concurrentなプログラムを表現する別のモデルも考えられるという点です．モデル化にはバリエーションがあるので「goroutineたちがmessage passing」だけが唯一のモデルというわけではないです．\ngoroutineというのは，概念的にはOSの提供するプロセスとかスレッドみたいなもので，実行中の処理を抽象化したものです．直感的にはOSのスレッドと思っていてもいいかもしれません．実態はちょっと違うんですけどね．この「抽象化された処理」同士がmessage passingによって情報を共有することでconcurrentな処理が実現できることになります．\nchannelというのは，goroutine間でのコミュニケーションをサポートするためにメッセージキューです．\ngolangは言語設計の根底にある思想として\n Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n を，掲げています．要するに「goroutineたちは共有メモリを設けるのではなくてmessage passingでコミュニケーションをとる」ように設計しようということです．\ngoroutineとchannelの設計と実装を眺める goroutine goroutineは「実行中の処理を抽象化したもの」と書きましたが，これは具体的には「計算に用いるstackと実行状態を保持している構造体」として実装されています．\ntype g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink // ,,, }  「それってOSの提供するプロセスとかスレッドと同じじゃないの？」\nそれは確かにそうなんですが，goroutineはOSの提供するプロセスとかスレッドと同レベルの存在ではなくて，goroutineは，OSの提供するスレッドに対してM:Nでマッピングされる「golangのruntimeが提供する，ユーザー空間で定義されたスレッド」として存在しています．golangのruntimeはgoroutineを管理していて「いつ，どのgoroutineを実行するか」を決定するschedulerとしての役割も担っています．つまりgolangのruntimeはユーザー空間で動く「ミニOS」のようなものな訳です．とは言いつつも，実際に実行されるためにはOSの提供するスレッドとして実行されなければいけないわけですから，goroutineはスレッドにマッピングされることになります．golangのschedulerはgoroutineとOSのスレッドを，M:Nでマッピングします．つまり複数のgoroutineが複数のOSスレッドとして実行されるわけです．1つのgoroutineが複数のOSスレッドとして実行されるし，1つのOSスレッドでは複数のgoroutineを実行することになります．\n   OS Process v.s. OS Thread v.s. Goroutine   となると，重要なのは「golangのruntimeがどのようなルールでgoroutineの実行計画を立てるのか」です．\ngolangのruntimeによるgoroutineのスケジューリング 登場するのはM，G，Pの三人．\n M  machineのM OSスレッドに相当する  G  goroutineのG  P  processorのP スケジューリングのコンテキスト（次どのGを実行するのか）を管理している 具体的に言えば，runnableなgoroutineのキューを管理しているのがP      G，M，P   まず，環境変数GOMAXPROCSの数だけM，Pがセットされます．以下では，GOMAXPROCS = 2とします．\n  runnableなGがPにenqueueされ，MはPからrunnableなGを1個取り出して実行します．\n  もし，queueにrunnableなGが0個になってしまったら，他のqueueから半分盗みます．\n  「自分のqueueが空になったら他のMの持つPから半分奪う」というスケジューリングアルゴリズムはwork stealingアルゴリズムと呼ばれています．golangのruntimeのスケジューラーはこのwork stealingアルゴリズムに従ってgoroutineのスケジューリングを行います．このアルゴリズムはCPUをたくさん使うような処理にスケジューリングには効率的である一方でI/O待ちを伴う処理（syscallの実行やネットワーク処理）とは相性が悪いです．そのため，いくつかの工夫がされています．\nまず，golangのruntimeに存在しているものを整理します．上で登場したM，G，Pの他にruntimeには\n グローバルキュー  各M-Pに対応するqueueとは別に存在するキュー 通常GがrunnableになるとPの持つキューに入るが，いくつかの状況ではこちらに入ります  sysmon  GOMAXPROCSの数だけのMとPの他に，sysmonという関数を実行し続ける特別なMが存在しています sysmonの実態は無限ループで，そのループの中でnetpollのチェックなどを行っています  P Idle List  暇なPのリスト  M Idle List  暇なMのリスト   syscallを実行した場合 時間のかかるsyscallを実行した場合，sysmonがそれを検知し，syscallを発行したGを実行しているMからPを切り離し，別のMにそのPをアタッチして処理を継続させます． syscall終了後は，まずP Idle Listを確認して暇そうにしているPを自身（M）にアタッチして処理を進めます．P Idle Listがからの場合はsyscallを発行したGをグローバルキューに突っ込み（このGはいずれGCされる），自身（M）はM Idle Listに入ります．\n  ネットワーク処理をした場合 ネットワーク処理の発生時にはnetpollerという仕組みに，ネットワーク処理を実行しているgoroutineが登録され，sysmonがnetpollerにポーリングします．ネットワーク処理が終了したらnetpollerからグローバルキューに追加されて，Mで続きを実行されるのを待つことになります．\ngolangの標準ライブラリが提供するネットワーキングのAPIはブロッキングな処理となっていますが，goroutineはOSスレッドに対してM:Nでマッピングされるため，netpollerをによってノンブロッキングな処理として実行されることになります．\n  channel channelはgoroutine間でのメッセージングをサポートするキューです．channelにはいくつかの面白い特徴があります．\n channelはgoroutine-safe  複数のgoroutineがあるchannelに同時にアクセスしても問題が発生しないようにロック機構が組み込まれています  channelはgoroutine間でFIFOなデータの受け渡しが可能です channelはその状況次第ではgoroutineをブロックしたりアンブロックしたりできます  バッファ0のchannelはgoroutineを同期させることができます．つまりあるgorotuineがchannelに書き込むと，相手のgoroutineがそれを読み込むまで書き込んだgoroutineの実行はブロックされるし，channelから読み込みたいgoroutineの実行は，相手のgoroutineが何かを書き込むまでブロックされます．   channelはhchanという名前の構造体で実装されています．\ntype hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex }  まず，構造体hchanのメンバーとしてlock mutexが見えるので，channelはgoroutine-safeです．複数のgoroutineが同時にアクセスしても問題が発生しないようになっています．goroutineがchannelに対して読み書きをしたくなったらロックを取ってから行うようになっているということです．\n上に示した通り，channelの実体は「circular queue（へのポインタ）」です．組み込みのmake()でchannelを作ると，実体はheap領域に確保され，それへのポインタが返されます．bufがバッファ先頭へのポインタで，sendx・recvxがそれぞれキューの先頭とお尻の番号になっています．\n   構造体hchan   なので，channelにメッセージが送り込まれたら，buf[0]にメッセージが入り，sendxがインクリメントされて1になります．続けてメッセージが2個送り込まれるとbuf[1]，buf[2]にメッセージが書き込まれ，sendxが0に戻ります．ここでメッセージが1個読まれるとbuf[0]の内容がdequeueてrecvxが1になります．特に難しいことはなく，一般のcircular queueの動作ですね．\nchannel間のメッセージングはとても直感的に実現することができます．channelにメッセージを書き込む時は，まずhchanのロックを取って，次にbufのお尻に送りたいデータをメモリコピーして，アンロック．channelからメッセージを読み込む時は，同様にまずhchanのロックを取って，bufの先頭をメモリコピーして，アンロック．とてもシンプルな動作です．\n実はこの挙動こそが，golangの\n Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n を実装している箇所と言えます．\ngoroutine間で共有しているのは構造体hchanだけです．しかもhchanはロックによって排他処理が施されるため，goroutine-safeです．hchanのbufに値を書き込む（つまりchannelに値を送る）・値を読み込む（つまりchannelから値を取り出す）動作は全てメモリコピーで行われます．goroutine間でやり取りする情報は（メモリを共有するのではなくて）メモリコピーして渡しましょうというのが，上の標語の実装と言えます．\nchannelはgoroutineの挙動をブロックしたりアンブロックしたりすることができます．バッファに空きが無いchannel（バッファ0のchannelや容量一杯データが書き込まれているchannel）に対してデータを送り込もうとすると，gopark()が実行されます．この関数は，golangのruntimeのスケジューラを呼び出して，バッファに空きが無いchannelにデータを送り込もうとしたgoroutineの状態をwaitにして別のgoroutineの実行を始めます．channelに対してデータを送り込むロジックの中に，goroutineをブロックするロジックが組み込まれているということになります．では，どうやってブロックされたgoroutineの実行を再開するのでしょうか．\nここで興味深いのが，gopark()の実行の直前に「どのgoroutineがどんな値を送り込もうとしていたのかをchannelの中に記録しておく」というところです．構造体hchanにはsendq，recvqというメンバがあり，そこに「このchannelにどのgoroutineがどんなデータを送り込もうとしているのか，取り出すのはどのgoroutineでどこに読み込もうとしているのか」という情報を保持しています．「このchannelにどのgoroutineがどんなデータを送り込もうとしているのか，取り出すのはどのgoroutineでどこに読み込もうとしているのか」を保持する構造体はsudogという名前になっています．なぜこの名前なのかはここのメーリスの一連の流れを読むとわかるかもしれませんよ．\n// sudog represents a g in a wait list, such as for sending/receiving // on a channel. // // sudog is necessary because the g ↔ synchronization object relation // is many-to-many. A g can be on many wait lists, so there may be // many sudogs for one g; and many gs may be waiting on the same // synchronization object, so there may be many sudogs for one object. // // sudogs are allocated from a special pool. Use acquireSudog and // releaseSudog to allocate and free them. type sudog struct { // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. g *g // isSelect indicates g is participating in a select, so // g.selectDone must be CAS'd to win the wake-up race. isSelect bool next *sudog prev *sudog elem unsafe.Pointer // data element (may point to stack) // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. acquiretime int64 releasetime int64 ticket uint32 parent *sudog // semaRoot binary tree waitlink *sudog // g.waiting list or semaRoot waittail *sudog // semaRoot c *hchan // channel }  gopark()によって受け取り手のgoroutineの実行が開始されると，受け取り手のgoroutineが，channelのsendqの中身を確認して，実行をブロックされてしまった送り手のgoroutineが最後にchannelに送り込もうとした値を（送り手側に代わって）受け取り手側がchannelのbufにコピーします．これはある種の最適化です．真面目に，送り手側の実行が再開されてからchannelにデータを送り込むことにするとchannelに対するロックを取る必要があり，排他処理をする回数が1回増えてしまいます．「誰がどんな値を送ろうとしていたのか」が自明であるならば，先にやってしまえという考えのようです．\nchannelから値を1個受け取ると，goready()が実行されて，スケジューラーが起動し，バッファに空きが無いchannelにメッセージを送ろうとしたgoroutineの状態をrunnableにセットして実行待ちのキューに入ります．\ngoroutineが空のchannelに対して読み込みを行おうとすると，そのgoroutineの動作はブロックされます．この挙動はchannelからデータを受け取るロジックであるrecv()関数内に記述されています．さらに面白いのが，「どのgoroutineが，どこに値を受け取ろうとしていたのか」をrecvqに保存していることです．これによって，channelにデータを送り込むgoroutineが，受け取り先のgoroutineのスタック領域を直接いじってデータを送り切ってしまうことが可能となります．goroutineの実体は（雑に言えば）stackを持つ構造体で，OSプロセスのスタック領域に置かれています．つまり別のgoroutineの持つstackを直接いじることが，channelでのデータのやり取りの限られた状況においてのみ許されているというのが興味深いです．\ngolangのchannel周りの実装を見て，\n 「排他処理を含む簡潔な実装の方が，排他処理なしの複雑な実装よりマシ．いくらパフォーマンスが良くても，それが複雑なコードでも良いことの理由にはならない」 「パフォーマンスの観点から，goroutineというユーザーレベルのスレッドを実装し（OSスレッドをブロックさせない），異なるgoroutineを跨いだメモリコピーを許す（その分実装がやや複雑になるがそれは許容する）」  という相反する考えが感じられます．つまり\n simplicityとperformaceには明確なtrade-offが存在する\n ということですね．\nおわりに 今回初めてruntimeをじっくり読みました．今まで概念として理解していたものの実体をコードとして掴めたので，とても楽しかったです．今回はgoroutineとchannel周りが中心だったので，次はスケジューラー周辺をもっとつぶさに見ていきたいと思います．\n","date":1572584876,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572584876,"objectID":"b23a273aaf77fc1dcb8ae6fefc8b2a15","permalink":"/post/internal-of-golang-concurrency-primitives/","publishdate":"2019-11-01T14:07:56+09:00","relpermalink":"/post/internal-of-golang-concurrency-primitives/","section":"post","summary":"goroutineとchannelの実装について眺めてみました","tags":["Golang","Goroutine","Channel","Concurrency","Parallelism"],"title":"Internal of Golang Concurrency Primitives","type":"post"},{"authors":[],"categories":[],"content":"golangとconcurrentなプログラミング 「concurrentな処理をどのように実現するか」はざっくり分けて2アプローチがある．\n1つは「shared-memory communication」．つまり処理を実行しているworker同士は，メモリを共有して，その共有しているメモリを用いてコミュニケーションを取るというもの．この場合，データ競合が発生しないようにロックを取ったりなどの排他処理を伴うことになって，大抵の場合実装が難しくなるとされている．\nもう1つは「message-passing communication」．つまり処理を実行しているworker同士は，メッセージをやり取りし合うことでコミュニケーションを取るというもの．\nそれぞれのアプローチでいろんな実装が世の中にはすでに存在していて，例えばCでconcurrentなプログラムを書こうとするとshared-memory communicationな形で書くことになる．一方でErlangは言語としてconcurrentなプログラミングをサポートしていて，Actorモデルを実装してる．\ngolangは，設計の時点でconcurrentなプログラミングは\n Do not communicate by sharing memory; instead, share memory by communicating\n という思想で実装することとしている．golangのconcurrentなプログラミングの実装は「Communicating Sequential Processes」と「$\\pi$-caluculus」を参考にしている．\ngolangは「concurrentなプログラミングを簡潔にわかりやすく記述すること」を言語の設計レベルからサポートしているので，concurrentな処理がとても書きやすくなっている．じゃあgolangではどうやってconcurrentなプログラミングをサポートしているのかというと，concurrentなプログラミングのプリミティブとしてgoroutine，channelを提供している．\n「golangはconcurrentな処理が書きやすいんだよね」という話をすると混乱しがちなのが， 「golangはconcurrentな処理を書くための道具を提供してくれるが，その実行がparallelであるかどうかはハードウェアに依存する」 という点．concurrentな処理は，parallelに実行することができるかもしれない（し大抵parallelに実行できるならそうしたほうがいい）が，それはハードウェアがparallelな実行をサポートしているか（例えばCPUが複数コア搭載しているか）によって決まってくる話であって，「プログラムがconcurrentであること」と「プログラムの実行がparallelであること」は関連はしているけれども，全く別の話．Rob Pike先生も\n Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once. Not the same, but related. Concurrency is about structure, parallelism is about execution. Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.\n って仰っている．\nHello, goroutine!  「golangではconcurrentなプログラムを書きやすい」ということだったので，実際にconcurrentなプログラムを書いてみると上の例みたいになる．concurrentに処理を実行するworkerは，golangの世界ではgorutineと呼ばれていて，goという魔法の言葉に続けてworkerで実行してほしい関数を呼び出せば，それでconcurrentな処理を書き下したことになる．なんて簡単なんだ...！\n上の例を実行すると，Hello! I'm mainって印字されて，もしかしたらHi! I'm goroutine!も一緒に印字される かもしれない．「かもしれない」っていうのは，goroutineは「あるgoroutineの親は自分の子供の処理が終わるのを待たない」ことになっている．この場合だとmainが親でgo fmt.Println(\u0026quot;Hi! I'm goroutine!\u0026quot;)が子供の関係になっていて，mainのfmt.Println(\u0026quot;Hello! I'm main\u0026quot;)の終了したら，その時点で子供の実行も終了させられてしまう．もし，子供のgoroutineが自己紹介し終わる前に親が自己紹介しきっちゃえば子供の自己紹介は印字されないし，親の自己紹介が終わる前に子供が自己紹介しきっちゃえば，親子両方の自己紹介が聞けることになる．\n「なるほど．でも親が先に終わっちゃうと子供も強制終了って，それどうにかならないの？」って思った方は賢くて，どうにかするためにgoroutine間でおしゃべりできるchannelというデータ構造が実装してある．\nNice to meet you, channel! channelはgoroutineたちが同期しながらconcurrentな処理を実行していくためのmessage-passingのメカニズムを提供してくれる．channelは「そのchannelを通じてやり取りするデータの型・バッファサイズ・メッセージのやり取りの方向」で定義されて，組み込み関数のmake()で簡単に作ることができる．\ngolangでは「channelはfirst-class value」として扱われる．つまりchannelは，他の値（例えばなんらかの構造体とかint型の変数とか関数とか）と同じレベルで扱われる．だから関数がchannelを返すなんてこともできるし，関数の引数にchannelを与えることもできるし，channelのchannelも定義できる．\nchannelの入出力の方向は\u0026lt;-という演算子で表現することになっている．\u0026lt;- cって書けばchannel cからデータを読み込むことになるし，c \u0026lt;- 1って書けばchannel cに1を書き込んだことになる．\nということで，channelを使った簡単ばプログラムを書いてみるとこんな感じになる．\n channel done を使って「僕は自己紹介終わったよママ」って子供のgoroutineが親mainに連絡することで，実行が同期されて両方の自己紹介が聞けるようになった．\nchannel doneは「bool値を通す，バッファが0の，読み書きができるchannel」として定義されている．golangでは「バッファが0のchannelに対する読み書きは，情報の送受信両者がコミュニケーションの準備ができるようになるまでブロックされる」ことになっている．なので，この例だと，確実に子供goroutineの自己紹介を聞くことができることになる．「バッファが0のchannelに対する読み書きは，情報の送受信両者がコミュニケーションの準備ができるようになるまでブロックされる」という挙動からバッファが0のchannelは「synchronous」と言える．\n下の例を実行すると，channel messageに1を送り終わってから，mainが1秒寝てしまうので，子供はchannel messageに続く2，3を送れなくて，止められてしまう．この挙動はsynchronousということになる．\n 一方で，バッファのあるchannelに対する読み書きは「バッファが空でないなら読み込みはブロックされない」「バッファが一杯でないなら書き込みはブロックされない」という挙動になっている．なので，バッファのあるchannelは「asynchronous」と言える．\n下の例を実行すると，channel messageはバッファを持っているので子供は1，2，3，4と（mainが眠りから覚める前に）立て続けに送ることができる．この挙動はまさしくasynchronousだ．\nOh, poor deadlock... 「goroutineもchannelもわかったので」ということで下みたいなプログラムを書くとdeadlockと言われてgolangのruntimeから叱られる．\n これはつまりどういうことかというと，golangのruntimeが「お前のプログラム実行したけど7行目でバッファのないchannelに42って送ってる（c \u0026lt;- 42）けど，それしたら受信者がいないし，受信者がいないと送信者も実行を進められないので，どうすることもできなくなっちゃったぞ」と怒っているのだ．\n「バッファのないchannelはgoroutine間の挙動をsynchronousにするもの」なので「受信者となるgoroutineのいない，バッファ0のchannelに値を送るとdeadlockする」のだ．\n今回の場合だと，受信者が存在しないことが問題なので，受信者となるgoroutineを作ればうまくいく．\n Let's range channels and close them. channelはrange構文を使って1つずつ値を取り出すということも記述できる．でも，rangeを使ってchannelから値を次々取り出すときはchannelを明示的にclose()しないといけない．\n チャンネルは組み込み関数のclose()で「閉じる」ことができて，閉じられたchannelに対して書き込みを行おうとするとgolangのruntimeはpanicして，閉じられたchannelに対して読み込みを行おうとするとそのchannelの扱う型のゼロ値が得られることになっている．\n「閉じられたchannelに対する読み込み」の特徴は「goroutineに処理の終了を通知させる機構」として応用することができる．大抵，こういう処理終了通知を行う場合は空の構造体struct{}のchannelを使う．なんてったって空の構造体は0byteだからね．\n あと，閉じられたchannelに対する読み込みはブロックされないので，そのまま処理は進む．\nMultiple channels and select. goroutineとchannelを使って実際になんらかの意味のあるプログラムを書こうとすると，たくさんのgoroutineとたくさんのchannelを扱うことになるのが普通である．大抵の場合「複数のchannelを同時に待ち受けたい」状況に出くわす．golangでは複数のchannelを同時に待ち受けるselect構文を用意している．\n select { case ...: ...}という構文で，複数のchannelを同時に待ち受け，値が書き込まれたchannelだけに対応するという，イベント駆動みたいな処理も簡単に書くことができるようになっている．\nchannel，お前最高かよ！ channelはマジで便利！でも使いこなすにはchannelの挙動をよく理解していないといけない．\n","date":1572528748,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572528748,"objectID":"d1a9aaedba5cb2d487581db7040bf32b","permalink":"/post/golang-channels-tutorial/","publishdate":"2019-10-31T22:32:28+09:00","relpermalink":"/post/golang-channels-tutorial/","section":"post","summary":"Golangの根っこに組み込まれているconcurrencyを実現する重要な部品であるchannelについて解説します！","tags":["Goalg","Channel","Tutorial"],"title":"Golang channels tutorial","type":"post"},{"authors":[],"categories":[],"content":" 日本語にすると\u0026hellip; 調べてみると，「Concurrentは並行」「Parallelは並列」と訳されるのが一般的らしいですが，日本語にしたところで違いが判然としないので，自分なりの解釈を書いてはっきりさせておきます．\nっと，その前に広辞苑によれば\u0026hellip;  【並行】並びゆくこと．また，並び行なわれること．「両案を並行して審議する」\n【並列】並び連なること．直列の対義語\n ダメだった．\nじゃあ，英英辞典（Oxford Dictionary）で引くと\u0026hellip;  concurrent\nExisting, happening, or done at the same time. ‘there are three concurrent art fairs around the city’\nparallel\n[Computing] Involving the simultaneous performance of operations. ‘highly parallel multiprocessor systems’\n これでもダメだった．\n僕の理解 Concurrent 並行とは「複数のタスクが，論理的に，同時に処理されているように見えること」\n具体的には，CPUが1コアの時代に，「一つのパソコンでブラウジングしながらメールが読める理由」を説明するのが「CPUがタスクをConcurrentに処理しているから」で，これが僕の「並行」の理解．\n細切れにたくさんの仕事をちょっとずつ進めて，全体として複数のタスクが同時に処理されているように見えるってだけで，実際に複数のタスクが同時に処理されているわけではない．\n「一人でいろんな仕事を同時に進めている様」が並行．\nParallel 並列とは「複数のタスクが，物理的に，同時に処理されていること」\n具体的にはマルチコアのプロセッサが，搭載している複数のプロセッサをちゃんと使い切って演算をしている様は，並列という言葉で形容できる．\n「複数人が同時に，それぞれの仕事を進めている様」が並列．\nちなみに，「並列であれば常に並行である」という主張もあるらしい．「複数人が同時に，それぞれの仕事を進めている様」は側から見ると「いろんな仕事を同時に進めている」ように見えるから，確かにそうかもしれない．\nRob Pike先生によれば\u0026hellip;  Concurrency is about dealing with lots of things at once.\nParallelism is about doing lots of things at once.\nNot the same, but related.\nConcurrency is about structure, parallelism is about execution.\nConcurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.\n なるほど\n結局なんだってばよ\u0026hellip;  Concurrency is a way of structuring your program to make it easy to understand and scalable\n and Parallelism is simply the execution of multiple goroutine in parallel\n  ref  Concurrency is not Parallelism  ","date":1572506814,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572506814,"objectID":"c7e7cdbec1dbcce85a754deadfc1e74c","permalink":"/post/concurrent-vs-parallel/","publishdate":"2019-10-31T16:26:54+09:00","relpermalink":"/post/concurrent-vs-parallel/","section":"post","summary":"似てるようで違うのでちゃんと区別したい","tags":["Concurrent","Parallel","Terminology"],"title":"Concurrent v.s. Parallel","type":"post"},{"authors":[],"categories":[],"content":"0. これは何 僕が最近研究している「並行グラフ処理系」に関連して，僕自身のテーマにおいて非常に参考になった論文であるParallelizing Sequential Graph Computations1について，その詳細をまとめました．なお，以下の資料の内容は大学のカリキュラムの一環として行われた発表会で用いたハンドアウトです．\n1. 背景 一台のメモリに載り切らないほど巨大なグラフに対する計算需要の高まりを受け，グラフ計算を並列実行するPregel2やGraphLab3をはじめとする処理系が考案された．これらは「各頂点を一台の計算機と見なし，頂点ごとに処理を実行し，頂点間でコミュニケーションをとりながら状態を更新し，その収束を以って全体の解とする」ようなThink Like A Vertex(TLAV)という計算モデルを実装している．\nしかし，既存のグラフアルゴリズムは並列実行されることを前提としていないため，これらの処理系を利用するためには実行したいアルゴリズムをTLAVに書き下す必要があるが，これは容易な作業ではない．グラフアルゴリズムはTLAVの登場以前から研究されていて，問題を解決する最適なアルゴリズムが既に存在しているにも関わらず，TLAVな処理系ではアルゴリズムの変換が伴うため，敷居が十分に下がったとは言えない．\nそこで，既存のグラフアルゴリズムのロジックをそのまま用いながらも，並列実行することができるような処理系 $GRAPE$ を提案する． $GRAPE$ では，計算モデルとして，既存の分散グラフ処理系が採用するTLAVではなく，Partial evaluation \u0026amp; Incremental Computationモデル(以下$GRAPE$モデル)を採用し，既存のアルゴリズムのロジックを変更することなく並列化させる．同時に，$GRAPE$モデルはTLAVと比較してコミュニケーションコストを少なく抑えることができることからより効率的な計算の実行が可能となる．\n2. 関連研究 分散グラフ処理の計算モデルの変遷と$GRAPE$モデルの位置付けを述べる．分散グラフ処理を実現する計算モデルとして以下の二つがよく用いられる．\nThink Like A Vertex 最初に提案された計算モデル．PregelやGiraph4，GraphLab5に実装されている．頂点ごとに処理を実行し，頂点間でコミュニケーションをとりながら状態を更新．全頂点の状態の収束を以って全体の解とする．\nThink Like A Graph (or Block Centric) TLAVを高速化しようとする研究の中で提案されたモデル．$n$個の頂点をまとめて扱うことでコミュニケーションコストを抑え，実行効率の向上を図る．Blogel6で実装されている．\nTLAVとBlock Centricモデルおよび$GRAPE$モデルを，処理単位の粒度，コミュニケーションコストの大小，プログラミングのしやすさという三つの観点から整理すると下表のようになる．\n   表1. 分散グラフ計算モデルの比較   3. Partial evaluation \u0026amp; Incremental computation $GRAPE$では，Partial evaluation \u0026amp; Incremental computationという計算モデルを採用している．これは，最初に部分グラフに対して実行したい処理を行って部分解を求め，その部分解の更新を繰り返していくことで全体の解を求めるというモデルである．\nPartial evaluation コンパイラによるプログラム最適化の文脈で登場し，XML文章中の要素を指定するXPathを分散環境下で評価する研究などでも取り上げられている7．\nIncremental computation 巨大な動的グラフ$G$に対するクエリ$Q$の応答速度を向上させる技術．グラフの変化$\\Delta G$から$Q(G \\oplus \\Delta G) = Q(G) \\oplus \\Delta O$を満たすようなクエリ出力の差分$\\Delta O$を求めることで，グラフ全体を用いて再計算することなく，変化後のグラフに対するクエリ結果を求める8．\n例えば，図1のような5ノードからなるグラフ$G$を三つの部分グラフ$F_1$，$F_2$，$F_3$に分割する．部分グラフは，それを構成するノードとそのノードを始点とするエッジの終点も含めるものとして与える．例えば，部分グラフ$F_1$は図2となる．ここで，グラフ$G$に対してノード$1$を始点とする単一始点最短経路問題(SSSP)を考える．$GRAPE$ではまず，部分グラフ$F_1$に対してダイクストラ法を用いて計算する．この結果は$G$全体に対するSSSPの解ではないが，この結果は全体の解のたたき台となっている．この「部分グラフ$F_1$に対するダイクストラ法の適用」がPartial evaluationである．\n    図1. 全体グラフ      図2. 部分グラフ $F_1$   $F_1$にダイクストラ法を適用することで表2を得る．ここで，ノード$4$および$5$のコストが計算されていることに注目する．これは，$F_1$のpartial evaluationの結果から，$F_3$の状態が変化した(表3におけるノード$4$および$5$の初期状態からの変化)ということであり，この変化を元に$F_3$に対してダイクストラ法を適用することで全体解に収束していく．これが，$GRAPE$のIncremental computationである．\n    表2. 部分グラフ$F_1$に対するPartial evaluation      表3. 部分グラフ$F_3$に対するIncremental computation   4. $GRAPE$ Partial evaluation \u0026amp; Incremental computationを図3のように組み上げることで処理系$GRAPE$を実現する．\n   図3. $GRAPE$   $GRAPE$の利用者は実行したい処理を，$\\sf PEval$(Partial evaluation相当)，$\\sf IncEval$(Incremental computation)相当，部分解をまとめる$\\sf Assemble$という三つのプログラムとして$GRAPE$に与える．$GRAPE$は一つの$\\tt coordinator$と複数の$\\tt worker$で構成され，$\\tt coordinator$は部分グラフ間の接続関係やどの$\\tt worker$がどの部分グラフを担当するかを管理している．$\\tt worker$は各自が担当する部分グラフに$\\sf PEval$や$\\sf IncEval$を適用する．\n$GRAPE$での演算は三つのフェーズから成る．まず$\\tt coordinator$がクエリの実行を受け付け，$\\tt worker$が各自が担当している部分グラフに対して$\\sf PEval$を実行する．次に, 各$\\tt worker$が部分グラフの状態変化を$\\tt coordinator$に通知する．$\\tt coordinator$は部分グラフ同士の接続関係を考慮し，対応する$\\tt worker$に変化を伝達する．知らせを受けた$\\tt worker$は，状態変化に基づく$\\sf IncEval$を実行し自分の担当している部分グラフの状態を更新する．$\\sf IncEval$は更新が発生しなくなるまで繰り返される．$\\sf IncEval$が収束すると，$\\tt coordinator$は各$\\tt worker$から部分解を回収し，最終的な出力を得る．\n5. $GRAPE$のアドバンテージ $GRAPE$は処理効率と$GRAPE$モデルの表現力において，既存の処理系に対してアドバンテージがある．$GRAPE$では部分グラフ間の状態変化をやり取りするコストのみで済むため，TLAVと比較して大幅にコミュニケーションコストが抑えられる．これによって，TLAVよりも効率的な処理が実行できる．さらに$GRAPE$で実行されるアルゴリズムのロジックは既存のものと変わらないため，既存のグラフ最適化技法を適用することができ，さらなる高速化も見込むことができる．加えて，$\\sf MapReduce$など他の分散計算モデルを$GRAPE$上に表現することも可能である．例えば$\\sf IncEval$でやり取りする情報を\u0026lt;key: value\u0026gt;として$\\sf PEval$と偶数回目の$\\sf IncEval$を$\\sf Map$に，奇数回目の$\\sf IncEval$を$\\sf Reduce$とすれば$\\sf MapReduce$を表現できる．\n6. 評価 $GRAPE$モデルがTLAVよりも\n 処理時間 コミュニケーションコスト グラフの規模に対するスケーラビリティ  の三点において，TLAVとの性能を比較し$GRAPE$モデルの優位性を検証した．プロセッサの数を64から192まで変化させながら，liveJournal9など複数の実世界グラフに対して単一始点最小経路問題をGiraph，GraphLab，Blogel，$GRAPE$で実行した結果を図4に示す．$GRAPE$はGiraph，GraphLab，Blogeと比べて484，36，15倍高速に処理を実行し，$\\tt worker$間でやり取りされるデータ量を0.07%，0.12%，0.7%に抑えられている．\nグラフの規模に対するスケーラビリティを，入力グラフを5Mノード50Mエッジから25Mノード250Mエッジまで変化させながら実行時間とコミュニケーションコストを計測した．その結果を図5の左二図に示す．グラフ規模に対して十分にスケールしていることがわかる．\n図5の右端図から，${GRAPE}$では，並列実行に伴うオーバーヘッドを考慮してもなお，既存のアルゴリズムに対する高速化技法の効果が得られることがわかる．\n    表4. 処理系ごとの実行時間とコミュニケーションコスト      表5. ${GRAPE}$のスケーラビリティーとグラフレベル最適化の効果   7. 結論 Partial evaluation \u0026amp; Incremental computationという計算モデルはグラフに対しても有効であり，この計算モデルを用いることで 既存のグラフアルゴリズムのロジックをほぼ変更することなく並列化を実現でき，分散グラフ処理系を利用する敷居を下げられる．そこでPartial evaluation \u0026amp; Incremental computationを実装する処理系$GRAPE$を提案する．Partial evaluationに相当する$\\sf PEval$とIncremental computationに相当する$\\sf IncEval$，部分解を集める$\\sf Assemble$を定義することで既存のグラフアルゴリズムの並列化を実現する．\n    Wenfei Fan, Wenyuan Yu, Jingbo Xu, Jingren Zhou, Xiaojian Luo, Qiang Yin, Ping Lu, Yang Cao, and Ruiqi Xu. 2018. Parallelizing Sequential Graph Computations. ACM Trans. Database Syst. 43, 4, Article 18 (December 2018), 39 pages. DOI: https://doi.org/10.1145/3282488 ^ Grzegorz Malewicz, Matthew H. Austern, Aart J.C Bik, JamesC. Dehnert, Ilan Horn, Naty Leiser, and Grzegorz Czajkowski.2010. Pregel: a system for large-scale graph processing. In Pro-ceedings of the 2010 ACM SIGMOD International Conferenceon Management of data (SIGMOD ’10). ACM, New York, NY,USA, 135-146. ^ Yucheng Low, Danny Bickson, Joseph Gonzalez, CarlosGuestrin, Aapo Kyrola, and Joseph M. Hellerstein. 2012. Dis-tributed GraphLab: a framework for machine learning and datamining in the cloud. Proc. VLDB Endow. 5, 8 (April 2012),716-727. ^ Giraph. http://giraph.apache.org/ ^ Yucheng Low, Danny Bickson, Joseph Gonzalez, CarlosGuestrin, Aapo Kyrola, and Joseph M. Hellerstein. 2012. Dis-tributed GraphLab: a framework for machine learning and datamining in the cloud. Proc. VLDB Endow. 5, 8 (April 2012),716-727. ^ Da Yan, James Cheng, Yi Lu, and Wilfred Ng. 2014. Blogel:a block-centric framework for distributed computation on real-world graphs. Proc. VLDB Endow. 7, 14 (October 2014), 1981-1992. ^ Peter Buneman, Gao Cong, Wenfei Fan, and Anastasios Ke-mentsietsidis. 2006. Using partial evaluation in distributedquery evaluation. In Proceedings of the 32nd international con-ference on Very large data bases (VLDB ’06), UmeshwarDayal, Khu-Yong Whang, David Lomet, Gustavo Alonso, GuyLohman, Martin Kersten, Sang K. Cha, and Young-Kuk Kim(Eds.). VLDB Endowment 211-222 ^ Wenfei Fan, Chunming Hu, and Chao Tian. 2017. Incremen-tal Graph Computations: Doable and Undoable. In Proceedingsof the 2017 ACM International Conference on Management ofData (SIGMOD ’17). ACM, New York, NY, USA, 155-169. ^ Snap. http://snap.stanford.edu/data/index.html ^   ","date":1572360869,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572360869,"objectID":"968af61da1967f4fa2f595bb94735e9d","permalink":"/post/parallelizing-sequential-graph-computations/","publishdate":"2019-10-29T23:54:29+09:00","relpermalink":"/post/parallelizing-sequential-graph-computations/","section":"post","summary":"僕が最近研究している「並行グラフ処理系」に関連して，僕自身のテーマにおいて非常に参考になった論文であるParallelizing Sequential Graph Computationsについて，その詳細をまとめました．","tags":["Parallel Graph Computation","Graph","Parallel Computation","GRAPE","Distributed Graph Processing"],"title":"Parallelizing Sequential Graph Computations","type":"post"},{"authors":[],"categories":[],"content":" ある人によれば\u0026hellip;  Simulation = For analysis and study\nEmulation = For usage as a substitute\nA simulator is an environment which models but an emulator is one that replicates the usage as on the original device or system.\nSimulator mimics the activity of something that it is simulating. It \u0026ldquo;appears\u0026rdquo; (a lot can go with this \u0026ldquo;appears\u0026rdquo;, depending on the context) to be the same as the thing being simulated. For example the flight simulator \u0026ldquo;appears\u0026rdquo; to be a real flight to the user, although it does not transport you from one place to another.\nEmulator, on the other hand, actually \u0026ldquo;does\u0026rdquo; what the thing being emulated does, and in doing so it too \u0026ldquo;appears to be doing the same thing\u0026rdquo;. An emulator may use different set of protocols for mimicking the thing being emulated, but the result/outcome is always the same as the original object. For example, EMU8086 emulates the 8086 microprocessor on your computer, which obviously is not running on 8086 (= different protocols), but the output it gives is what a real 8086 would give.\n また別の人によれば\u0026hellip;   Simulator is broader than Emulator\n Simulator tends to imitate/model more global processes/things in general with ability to narrow the imitation down (e.g. capacitor simulator with presets representing some known models)\n Emulator tends to imitate certain hardware devices with certain specification, known characteristics and properties (e.g. SNES emulator, Intel 8087 or Roland TB-303)\n   語源を辿ると\u0026hellip;   emulate is \u0026ldquo;to be equal\u0026rdquo; (looks like more aggressive and straightforward - rivalry) simulate is \u0026ldquo;to be similar\u0026rdquo; (looks like more sly and tricky - imitation)   日本語だと\u0026hellip;  Emulation: （代替可能なレベルでの）模倣 Simulation: 模擬  かな？🤔\nReference  Simulator or Emulator? What is the difference?  ","date":1572359078,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572359078,"objectID":"705d566c5c9beb942ffe89b0794f72f7","permalink":"/post/simulator-vs-emulator/","publishdate":"2019-10-29T23:24:38+09:00","relpermalink":"/post/simulator-vs-emulator/","section":"post","summary":"似て非なるもの","tags":["Simulator","Emulator","Terminology"],"title":"Emulator v.s. Simulator","type":"post"},{"authors":[],"categories":[],"content":" GitHub上でのmerge GitHub上で行えるmergeには3種類あります．\n Create a merge commit Squash and merge Rebase and merge  これらは，「merge commitの有無」「merge commitのauthorが誰になるのか」などの点で微妙に異なります．\n   Command merge commitの有無 merge commitのauthor merge元のbranchのcommit log     Create a merge commit 有 merge先 残る   Squash and merge 有 merge元 残らない   Rebase and merge 無  残る    Create a merge commit 「Create a merge commit」では，git merge --no-ffでmergeすることになります．つまり，merge先に新たなcommitが作成され，そのcommitがmerge元のcommitを取り込みます．このとき作成されるmerge commitのauthorはmerge先のauthorとして記録されます．\nこの方法は\n 「何をmergeしたのか」がmerge commitという形で記録として残る merge元のbranchがそのまま残るので変更箇所を追いやすい merge後に，merge元のbranchを削除したとしても，このbranchのcommit logがmerge先に残る  という特徴があります．わかりやすい一方で，「merge commitのauthorがmerge元ではない」のが（個人的に）「その人の頑張りを讃えたいのになぁ」とか思っちゃったりしてちょっと申し訳ない気がするとかしないとか．\n   Create a merge commit   Squash and merge 「Squash and merge」では，git merge --squashでmergeすることになります．つまり，merge元のcommitを一つのcommitにまとめた上で，merge先にmerge commitとして先頭に追加されます．このときのmerge commitのauthorはmerge元のauthorとなります．\nこの方法は\n 「何をmergeしたのか」がmerge commitという形で記録として残る 複数のcommitをまとめて一つにできるのでmerge先のcommit logがわかりやすい  という特徴があります．一方で，一度commitをまとめてしまうと，「どの変更が誰によってどのcommitで行われたのか」という情報が失われてしまうことになります．他の人の複数のcommitを一つのcommitに押し込むことになるので，個人的には若干怖さがあります．\n   Squash and merge   Rebase and merge 「Rebase and merge」では，まずmerge元のブランチにあるcommit列に対してgit rebaseして，commit列が一列になったところでfast-forwardの形でmergeが実行されます．\nこの方法は\n mergeした結果，merge先のcommit logが一直線で見やすい merge commitが作成されない  という特徴があります．\n   Rebase and merge   Reference  About merge methods on GitHub  ","date":1572346258,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572346258,"objectID":"23d6b53e02b5322745a0e712092cb5bf","permalink":"/post/three-kinds-of-merge-on-github/","publishdate":"2019-10-29T19:50:58+09:00","relpermalink":"/post/three-kinds-of-merge-on-github/","section":"post","summary":"GitHub上で実行できる3種類のmergeについて「どのようなものなのか？」をまとめました．","tags":["GitHub","Git","Tips"],"title":"GitHub上でのmerge","type":"post"},{"authors":[],"categories":[],"content":" Federated Social Webとは？ Federated Social Webとは，誤解を恐れず端的に言えば「分散Twitter」である．\n「分散Twitter」とは何かを説明するには，Twitterと対比するのがわかりやすい．TwitterはTwitter社が提供しているマイクロブログサービスで，ユーザーはTwitter社が管理するサーバー上に展開されているTwitterというシステム内にアカウントを作成し，テキストメッセージや動画像を投稿（ツイート）したり拡散（リツイート）したりすることができる．アカウントごとにタイムラインというインタフェースが提供され，ユーザーはタイムラインを通じてコンテンツを閲覧することができる．Twitterはアカウントを「Followする」という機能も実装している．これは「他のアカウントの投稿を自分のタイムラインに表示する機能」でユーザーは好みのコンテンツを投稿してくれるアカウントをフォローすることで，より簡単に好みのコンテンツを発見・消費することができるようになる．\nTwitterの抱える問題点は「Twitterというサービスが中央集権的である」という点である．「Twitterというサービスが中央集権的である」とは\n 「TwitterというシステムはTwitter社の管理するマシン上でのみ展開されているため，そのマシンが落ちるとTwitterというシステム全体が落ちてしまう（単一障害点）」 「ユーザーがTwitterに投稿した任意のコンテンツやデータは基本的にTwitter社の管理するマシンにしか残らない」 「ユーザーは投稿内容についてTwitter社の決めるルールに従わなければならない（コンテンツの価値判断についての自由がユーザーから剥奪される．少なくともTwitter社がコンテンツに対して検閲を行えばそれを回避する手段は存在しない）」 「Twitterというサービスを提供するTwitter社の決めるルールに，ユーザーの全員が従わなければならない」 「TwitterというサービスのしようがTwitter社の一存で決まるため，Twitterというシステムに乗っかろうとする外部の開発者は地位的にTwitter社の下につくことになる」 「Twitterの実装は公開されない（ので，ユーザーがなんらかの不具合に直面しても，ユーザー自身で修正することが根本的に不可能）」  ということ．\n「Twitterというシステムの管理者がTwitter社しかいない」と「ユーザーはTwitter社の決めたルールの中でした活動できない」ということになる．これは殊「コンテンツ共有」という文脈において大きな問題になる可能性がある．というのも，「コンテンツに対する価値判断やそれを発表することは，基本的に人間に与えられた自由である」からだ．いわゆる「表現の自由」ってやつだ．細かなことを言えば，法律が保証する「表現の自由」の範囲は「公共の福祉を侵害したり他者の自由を侵害しない」ような表現の自由であるようだが．ここで大事なのは，表現の自由を制約するのは「公共の福祉や他社の自由を侵害するかしないか」という社会的な合意であって，Twitterといった一私企業の決めたルールではないということだ．現状のSNSはその点で問題を抱えている（と自由を求めるユーザーは主張している）．無論，Twitter社の決めたルールの範囲内で楽しむので十分というユーザーもいるだろうし，なんならそっちの方が多数派な気もするが．\nそんな問題意識からFederated Social Webという概念が登場している．Federated Social Webが実現したいのは「中央集権ではない形で社会的な人間の在りようをインターネットの世界に実装すること」である．Federated Social Webでは，先に挙げた目的を「Cleint-ServerモデルとServer-Serverモデルの組み合わせ」で実現しようとしている．\n   Fededated Social Web   Federated Social Webでは「既存のTwitterのような仕組みを提供するserverが不特定多数の管理者（これは組織でも個人でもいい）によって提供され，彼らが提供するシステムにユーザーが乗っかる」というモデルである．\n「Federated」を英英辞典で引くと\n (of a country or organization) set up as a single centralized unit within which each state or division keeps some internal autonomy.\n とある．つまり，Social Networkingに必要な機能を提供するserverが，（単一の管理者によって定められたルールによって動くのではなくて）複数の管理者が自由に定めたルールに基づいて統治・管理されるということだ．ユーザーは自分の納得するルールで運用されているserverにぶら下がれば，そのユーザーにとって十分な自由を享受できるし，いやになれば異なるルールで動いている他のserverに移ることだって可能だ．さらに言えば「オレオレルール」で運用されるオレオレSNSを構築することだって許されている．\nActivityPubとは ActivityPubはFederated Social Webを実現する際の通信プロトコルだ．ActivityPubは「あるserverとそれにぶら下がっているclient間の通信プロトコル」と「連合を組むserver間の通信プロトコル」の2つのプロトコルを内包している．\n「あるserverとそれにぶら下がっているclient間の通信プロトコル」は，通常のSNSにおいて必要な投稿だとか他の人の行動のお知らせとかを受け取るために必要な通信を規定しているもの．\n「連合を組むserver間の通信プロトコル」は，不特定多数の管理者が運営するserver間で情報を共有するための通信を規定するもの．これがあることで，「Federated」なSocial Webが初めて実現できる．\nActivityPubでは，ユーザーは「他のユーザーからのお知らせを受け取るinboxと自分のシステム上での行動を他の人に通知するoutboxを持つActor」としてモデル化される．inbox/outboxの実体はwebの世界で言うところのURLに過ぎず，さらに言えばclientがserverにGET/POSTする際のapi endpointでしかない．あctivityPubではどんな形式のデータをやりとりするかも規定している．より具体的に言えば「SNSをWeb上で実現する際のJSONメッセージフォーマット」を規定するActivityStreamsの上にActivityPubは規定されている．\n要するに，client-server間の通信とclient-client間の通信のそれぞれについて，ActivityStreamsが定義するデータを用いたSNS上におけるActorの行動に対するCRUDを定義しているのがActivityPubである．\n疑問 不特定多数の管理者がそれぞれのルールでSNSを提供するときに，それらSNS同士がやり取りをするための統一的なデータ形式・APIを規定しているのがActivityPubということになるが，各SNSが独自機能を実装して独自データフォーマットを追加したときはどのように対応するのだろう．\nActivityPubは最低限実装されるべきAPIとして整備されるにしても，独自データフォーマットについては共有する方法とかは規定していない．ActivityPubには「JSON-LDを用いてActivityStreamsは拡張可能である」としている．やり取りされるJSONメッセージに未知のフィールドが存在していたら，無視するか適当に解釈するかしかないので，どうするのだろう．ただ，SNSというある程度要求されるAPIがサービスから予測がつくしそれ以上の独自性がなさそうという感覚からすればActivityStreamsで十分なのかもしれない．この点はActivityStreamsを読んでみないとわからないと思うので気が向いたらやろうかな．\nMastodon MastodonはActivityPubを実装しているウェブアプリケーションの1つ．ちょっと前にちょっと流行った．Mastodonの面白いところは，Social Webにおけるグローバルなuser identityをメールアドレスみたいな形式で表現できるようにしたこと．Web上でのIdentityはサービスと強固に結びついていて，現在でもGoogle，Facebook，GitHub認証のサービスがたくさんある．「私はAliceです」と，ただそれだけで主張することができるURLがWeb上には存在していなくて，「FacebookのAliceさん」とか「GoogleのAliceさん」という風にしか自分のことを表現できていない状態にある．Federated Social Webの実装例であるMastodonでは，\u0026lt;user_id\u0026gt;@\u0026lt;federation_id\u0026gt;みたいな形でユーザーのグローバルなIdentityを与えることにしていて，これは賢いなと思う．\n","date":1572252565,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572252565,"objectID":"483ffe32be9d68876584fd344ad24aaa","permalink":"/post/what-is-activitypub/","publishdate":"2019-10-28T17:49:25+09:00","relpermalink":"/post/what-is-activitypub/","section":"post","summary":"ActivityPubが目指すFederated Social Webについて考えてみました","tags":["ActivityPub","Federated Social Web","Distributed Social Network","Mastodon","Decentralization"],"title":"Federated Social WebとActivityPub","type":"post"},{"authors":[],"categories":[],"content":" 共通鍵暗号 暗号化・復号で同一の鍵を用いる暗号化方式\nシナリオ  Aliceが秘密鍵$key$を作成し，Bobに安全に共有 Aliceがメッセージ$m$を$key$で暗号化$c = Enc(m, key)$し，Bobに送信 Bobが受け取った暗号文$c$を$key$で復号$m = Dec(c, key)$して平文$m$を得る  共通鍵暗号の満たすべき性質  正当性  $m = Dec(Enc(m, key), key)$が成立すること  秘匿性  暗号文$c$から平文$m$に関連する情報が得られないこと   共通鍵暗号に対する攻撃モデル 暗号文単独攻撃：Ciphertext Only Attack 攻撃者が「解読対象の暗号文$c^*$」と「盗聴した暗号文$c_1$，$c_2$，$c_3$\u0026hellip;$c_k$」を手元に持っている状況での攻撃．通信路の盗聴という攻撃に相当．\n既知平文攻撃：Known Plaintext Attack 攻撃者が「解読対象の暗号文$c^*$」と「（同一の鍵で暗号化された）ランダムな平文と暗号文の対$(m_1, c_1)$，$(m_2, c_2)$，$(m_3, c_3)$\u0026hellip;$(m_k, c_k)$」を手元に持っている状況での攻撃．過去の平文が特定済みであるような状況での攻撃に相当．\n選択平文攻撃：Chosen Plaintext Attack 攻撃者が「解読対象の暗号文$c^*$」を持ち，「攻撃者が選んだ任意の平文に対応する暗号文を自由に入手できる」ような状況での攻撃．\n選択暗号文攻撃：Chosen Ciphertext Attack 攻撃者が「解読対象の暗号文$c^$」を持ち，「攻撃対象の暗号文$c^$を入手する前の時点で，攻撃者が自分の選んだ暗号文に対応する平文を入手することができる」ような状況での攻撃．\n適応的選択暗号文攻撃：Adaptive Chosen Ciphertext Attack 攻撃者が「解読対象の暗号文$c^*$」を持ち，「攻撃者が選んだ任意の暗号文に対応する平文を自由に入手できる」ような状況での攻撃．\n鍵全数探索攻撃に対する共通鍵暗号の安全性 秘密鍵が$k$bitであるような共通鍵暗号では，$2^k$個の鍵を全部試せば必ず秘密鍵を得ることができる．共通鍵暗号では「鍵全数探索攻撃よりも効率的に秘密鍵を求めるアルゴリズムが存在しないこと」が安全性に対する条件である．\nさまざまな共通鍵暗号  ストリーム暗号  平文を小さい単位で順次処理していく方式 アルゴリズムを実行する回数が1回  ブロック暗号  平文を一定の大きさの単位で処理していく方式 アルゴリズムを実行する回数がブロックの個数分   バーナム暗号  👍  情報理論的安全性を持つ  たとえ，鍵全数探索を実行できる無限の計算能力を持っている攻撃者であっても解読できない（どれが本当の平文なのかがわからない）  処理が「平文と鍵でxor」と単純なので非常に高速  👎  少なくとも平文と同じ長さの秘密鍵が必要になるし，基本的に鍵は使い捨てなのでいくら鍵を用意しても足りないし，そもそもこの秘密鍵を安全に共有できるなら暗号化する必要がない 鍵の生成に「真性乱数」を用意しなければならず，長い鍵を作るには手間がかかる   ストリーム暗号  👍  バーナム暗号と比べて（安全性をやや犠牲にしながらも）効率性を向上  👎  擬似乱数生成器の安全性がストリーム暗号の安全性に直結する  過去の系列を見て未来の系列が予測できてしまえば解読されてしまう 擬似乱数生成器の初期化に用いる秘密鍵を特定されてしまうと解読されてしまう    ","date":1572250776,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572250776,"objectID":"933f01d72df16835e756a93a571c6943","permalink":"/post/symmetric-key-encription-scheme/","publishdate":"2019-10-28T17:19:36+09:00","relpermalink":"/post/symmetric-key-encription-scheme/","section":"post","summary":"暗号技術学習メモ #2","tags":["Cryptography","Memo","Symmetric Key Encryption"],"title":"共通鍵暗号","type":"post"},{"authors":[],"categories":[],"content":" 暗号の基礎技術 暗号技術の中でも基礎となるもの．\n 暗号 鍵配送 ハッシュ関数 メッセージ認証コード デジタル署名 擬似乱数生成器  暗号 暗号とは，「正当な送信者と受信者以外に内容を秘匿する技術」のこと．送信者は平文に対して，なんらかの操作を施すことで，暗号文を生成する．この過程を暗号化という．一方で，受信者は暗号文に対してなんらかの操作を施すことで平文を得る．この過程を復号という．\n鍵配送 鍵配送とは，暗号化や復号に用いる鍵を安全に配送・共有するための技術や方式のこと．鍵は「第三者に知られないように」配送する必要があります．\nハッシュ関数 ハッシュ関数とは，任意長のビット列を入力として固定長のビット列を出力する関数のこと．同一の入力に対して同一の出力をする一方で，異なる入力に対して異なる出力となり，異なる入力に対して同一の出力にならないという性質が求められる．\nメッセージ認証コード メッセージ認証コードとは，「伝送路上を通ってきたデータが改ざんされていないこと」「データが期待した通信相手から送信されていること」を検証するための技術のこと．\nデジタル署名 デジタル署名とは，契約書における物理的なサインのデジタル版で，ユーザー認証とデータ認証を同時に実現する技術のこと．メッセージの改ざんを防ぎ，メッセージに対する署名は署名した本人でしか生成できないことから，後から署名者が署名した契約について否認することを防止することができる．\n擬似乱数生成器 真の乱数ではないにしても，暗号論的に安全とみなせる乱数列を生成するための技術のこと．\n","date":1572234048,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572234048,"objectID":"171b152bec97767e38aadfdd4c806b24","permalink":"/post/basic-cryptographic-technologies/","publishdate":"2019-10-28T12:40:48+09:00","relpermalink":"/post/basic-cryptographic-technologies/","section":"post","summary":"暗号技術学習メモ #1","tags":["Cryptography","Memo"],"title":"暗号の基礎技術","type":"post"},{"authors":[],"categories":[],"content":" 情報セキュリティの構成要素 「情報セキュリティ」の言葉の指し示す意味範囲はOECDの情報セキュリティガイドラインやISO/IEC TR133351として国際的に定義されている．\nISO/IEC TR13335にて情報セキュリティとは下記6要素のことを指すとされている．\n 機密性 Confidentiality 完全性 Integrity 可用性 Availability 責任追跡性 Accountability 真正性 Authenticity 信頼性 Reliability  機密性 Confidentiality  意味  意図した相手以外に情報が漏れないこと  リスク  盗聴や内部からの情報漏洩  対策  暗号技術   完全性 Integrity  意味  情報が正確であること  リスク  情報の改ざん，ノイズによるビット反転・ビットの欠落  対策  誤り訂正符号，ハッシュ関数，メッセージ認証コード，デジタル署名   可用性 Availability  意味  ある情報にアクセスすることが許されている主体が，任意の時点で情報にアクセスすることができること  リスク  システムへの過負荷，災害，意図しないロック  対策  システムの多重化，クラウド化，負荷分散   責任追跡性 Accountability  意味  ユーザやシステムの振る舞いについて説明が可能であること  リスク  ログの改ざん，否認  対策  ロギング，デジタル署名（否認防止）   真正性 Authenticity  意味  観測されるユーザやシステムの振る舞いが，その主体によるものであること（なりすましではない）  リスク  なりすまし  対策  認証，デジタル署名（なりすまし防止）   信頼性 Reliability  意味  システムが一貫して動作すること  リスク  盗聴や内部からの情報漏洩  対策  システムの多重化，負荷の監視    正確には企業のセキュリティリスクを査定する際のガイドラインを定めたものになっている．通称GMITS（Guidelines for the Management for IT Security） ^   ","date":1572231267,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572231267,"objectID":"856dc76386ac6865a6fbad2e2fc6b522","permalink":"/post/six-elements-of-infomation-security/","publishdate":"2019-10-28T11:54:27+09:00","relpermalink":"/post/six-elements-of-infomation-security/","section":"post","summary":"暗号技術学習メモ #0","tags":["Security","Memo"],"title":"情報セキュリティの構成要素","type":"post"},{"authors":[],"categories":[],"content":" ありがちな会話 「Web Application Frameworkと言ったら，やっぱりRuby on Railsだよね！」\n「Webのフロント開発ではjQueryってライブラリがあってだな\u0026hellip;」\n「最近だと，FacebookがJavascriptのフレームワークとしてReactを発表してるよね」\n「ReactよりAngular JSの方がいいよ」\nWeb系の技術の話では，たくさんのFrameworkだのLibraryだのが提案されて使用されていると思います．僕なんかも初めて聞くものがあれば，すぐにググってその正体を知ろうとするのですが，どれもこれも「これは便利なWeb Frameworkです」ぐらいしか教えてくれません．Frameworkの正体って一体何なのでしょうか．気になったので調べてみました．\nLibrary v.s. Framework Library Libraryは，コードの再利用を目的とした「便利な関数やクラスの（ただの）コレクション」のようなものです．Libraryに含まれる関数やクラスは，ある特定の処理を達成するロジックを含んでいて，開発者がそれらを利用することで開発を進めていくことになります．例えばグラフアルゴリズムのライブラリなら，Dijkstra法とかBellman-Ford法を実装した関数が含まれていて，開発者がその関数を利用することでアプリケーションを開発します．アプリケーションの開発者が書いているロジックにライブラリの関数が利用されるので，アプリケーションの制御は開発者側にあります．\nLibraryを用いることで，他の人の仕事の恩恵に与りながら開発を進めることができます．これはとても嬉しいことです．開発の速度が上がります．\n要するに「Libraryのコードを開発者が利用する」のがLibraryです．\nFramework Frameworkは， (初期化から実際の処理，終了といった) アプリケーションの制御は 全てFramework側にあります ．アプリケーションを開発者は，Frameworkが要求するロジックを部品としてFrameworkに提供することになるわけです．Frameworkはアプリケーションの骨格を定義しているともいるかもしれません．外枠だけ定義しているのです．このFrameworkの持つ性質は，ソフトウェア工学的には「制御の反転 IoC (Inversion of Control)」と呼ばれています．\nFrameworkを用いることで，アプリケーション開発者は設計についてあれやこれや悩む必要がなくなります．Frameworkの要求に従っていれば，それなりの品質のシステムが勝手に出来上がることになるからです．また，Frameworkに則ってアプリケーションを開発していくと，コードに一貫性が生まれます．これはコードに可読性を与え，メンテナンスがしやすくなります．\n一方で，Frameworkは「制約の集合」でもあります．アプリケーションの全体としての制御が開発者の自由にできないわけですから，Frameworkを導入するならばFrameworkの課すルールを理解する必要があります．ルールを理解するのには時間がかかるものですし，Frameworkのルールに窮屈さを感じることもあるかもしれません．小規模なその場限りの開発現場などでは，この制約がFrameworkのメリットを上回ることがあるので，Frameworkを導入しないこともあるでしょう．\n要するに「Frameworkが開発者のコードを利用する」のがFrameworkです．\n   LibraryとFrameworkとあなた   参考  ソフトウエアのフレームワークとはなにか (日経XTECH) フレームワークとライブラリの違い (Qiita) The Difference Between a Framework and a Library (freeCodeCamp) What is the difference between a framework and a library? (stackoverflow)  ","date":1572011115,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1572011115,"objectID":"e54cb1b7589f8c07b1423f581d1a62ba","permalink":"/post/what-is-the-difference-between-library-and-framework/","publishdate":"2019-10-25T22:45:15+09:00","relpermalink":"/post/what-is-the-difference-between-library-and-framework/","section":"post","summary":"ちゃんと説明できますか？","tags":["Framework","Library"],"title":"FramworkとLibraryの違い","type":"post"},{"authors":[],"categories":[],"content":" flagパッケージ Golangでは，標準パッケージとしてコマンドライン引数を扱うflagパッケージが付属しています．「痒い所に手が届く」とはこのことですね．\nフラグの立っていないコマンドライン引数の取得 Parse()の後にArgs()で[]stringとして取得できます．\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { flag.Parse() args := flag.Args() fmt.Println(args) }  $ go run with-no-flag0.go a b c [a b c] $ go run with-no-flag0.go 1 2 3 [1 2 3]  $n$番目の要素のみを取り出したい場合はArg(n)でstringとして取得できます．$n$番目の要素が存在しない場合は\u0026quot;\u0026quot;が返ってくるようです．\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { flag.Parse() fmt.Println(flag.Arg(0), flag.Arg(1)) }  $ go run with-no-flag1.go hoge fuga hoge fuga $ go run with-no-flag1.go 1 1  フラグの立っているコマンドライン引数の取得 型名()もしくは型名Var()で，フラグを定義したのち，Parse()でそれぞれの変数を取得できます．\nフラグの定義は「フラグ名」「デフォルト値」「ヘルプメッセージ」で行います．\n型名()の場合は，指定した型へのポインタが返ってきます．\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { var ( i = flag.Int(\u0026quot;int\u0026quot;, 0, \u0026quot;int flag\u0026quot;) s = flag.String(\u0026quot;str\u0026quot;, \u0026quot;default\u0026quot;, \u0026quot;string flag\u0026quot;) b = flag.Bool(\u0026quot;bool\u0026quot;, false, \u0026quot;bool flag\u0026quot;) ) flag.Parse() fmt.Println(*i, *s, *b) }  $ go run with-flag0.go -int 2 -str hello -bool true 2 hello true $ go run with-flag0.go 0 default false  型名Var()の場合は，引数で渡した変数に代入されます．また，適切な値を渡さないと怒られます．ダメな理由も教えてくれるので怒られがいがあります．定義していないフラグも受け付けてくれません．\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { var ( d time.Duration f float64 ) flag.DurationVar(\u0026amp;d, \u0026quot;dur\u0026quot;, 1 * time.Second, \u0026quot;duration flag\u0026quot;) flag.Float64Var(\u0026amp;f, \u0026quot;float\u0026quot;, 0.1, \u0026quot;float flag\u0026quot;) flag.Parse() fmt.Println(d, f) }  $ go run with-flag1.go -dur 1h -float 2.3 1h0m0s 2.3 $ go run with-flag1.go -float str invalid value \u0026quot;str\u0026quot; for flag -float: strconv.ParseFloat: parsing \u0026quot;str\u0026quot;: invalid syntax Usage of /var/folders/.../with-flag1: -dur duration duration flag (default 1s) -float float float flag (default 0.1) exit status 2  フラグの書き方 フラグの書き方は次の2通りが可能です．\n -flag value -flag=value  ただし，Bool値を取得する場合はflag=valueを使った方がいいかもしれません．というのも， フラグの型がBool値かつ引数が続かない場合，フラグが立っただけでtrueとなるからです．\nつまり，フラグを立ててBool値を取得したい場合は-bool=true/-bool=falseとしなければならないということです．-bool falseではtrueとなってしまいます．また-bool false以降の引数が全てフラグ無しで渡された引数として評価されてしまいます．注意が必要ですね．\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { var ( i = flag.Int(\u0026quot;int\u0026quot;, 0, \u0026quot;int flag\u0026quot;) s = flag.String(\u0026quot;str\u0026quot;, \u0026quot;default\u0026quot;, \u0026quot;string flag\u0026quot;) b = flag.Bool(\u0026quot;bool\u0026quot;, false, \u0026quot;bool flag\u0026quot;) ) flag.Parse() fmt.Println(*i, *s, *b) }  $ go run with-flag0.go -bool false -int 123 -str abc # falseを含むそれ以降が全て非フラグで渡されたコマンドライン引数として扱われる 0 default true $ go run with-flag0.go -bool=true -int 123 -str abc 123 abc true $ go run with-flag0.go -bool=false -int 123 -str abc 123 abc false  ちなみに-hでヘルプを表示してくれます．賢いですね．\n$ go run with-flag0.go -h Usage of /var/folders/.../with-flag0: -bool bool flag -int int int flag -str string string flag (default \u0026quot;default\u0026quot;) exit status 2  コマンドライン引数の個数を数える NArg()で非フラグなものを，NFlag()でフラグなものをカウントできます．\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { flag.Int(\u0026quot;int\u0026quot;, 0, \u0026quot;int flag\u0026quot;) flag.String(\u0026quot;str\u0026quot;, \u0026quot;default\u0026quot;, \u0026quot;string flag\u0026quot;) flag.Bool(\u0026quot;bool\u0026quot;, false, \u0026quot;bool flag\u0026quot;) flag.Parse() fmt.Println(\u0026quot;non flag:\u0026quot;, flag.NArg()) fmt.Println(\u0026quot;flag:\u0026quot;, flag.NFlag()) }  $ go run flag-test.go -int 1 -str foo -bool=true a b non flag: 2 flag: 3 $ go run flag-test.go -int 1 -str foo -bool true a b non flag: 3 flag: 3 $ go run flag-test.go -bool true -int 1 -str foo a b non flag: 7 flag: 1 $ go run flag-test.go a b c -bool=true -str foo non flag: 6 flag: 0 $ go run flag-test.go -bool=true -str foo a b c non flag: 3 flag: 2 $ go run flag-test.go a b c non flag: 3 flag: 0 $ go run flag-test.go -bool=true -str foo non flag: 0 flag: 2  ","date":1571997871,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1571997871,"objectID":"0bf003175f088b27d9d436b60a11ab98","permalink":"/post/handle-commandline-args-with-flag-package/","publishdate":"2019-10-25T19:04:31+09:00","relpermalink":"/post/handle-commandline-args-with-flag-package/","section":"post","summary":"flagパッケージでコマンドライン引数を賢く扱おう！","tags":["Golang","Tips"],"title":"🚩flagパッケージでコマンドライン引数を扱う","type":"post"},{"authors":[],"categories":[],"content":" はじめに 最近はもっぱら卒論の実装ばかりやっています，zakです．\nプログラム書くのって難しいですよね．僕にとってはとても難しいので，わからないことがあったらデキる人のブログを参考にさせていただいたりしています． そんな中で，自分もコードを書くことが増えてきて，そこで得た知識をなんらかの形で発信できないかなと思って，このブログを思いつきで始めました．\n採用技術 このブログはサイトジェネレータとしてHugo，ホスティングサービスとしてGitHub Pagesを採用しています．\nHugoはGolangで記述されたオープンソースの静的サイトジェネレーターです．設定をtomlで書いて，記事をMarkdownで書いて，それをHugoがHTMLその他ファイルに爆速でしたためてくれます．真面目にウェブサイトを作ろうとすると，「書きにくいHTMLで文章を書いて，CSSで見栄えを整えて」という感じで作っていくことになります．HTMLってあんまり洗練されていなくて人間にとっては読みずらいですよね．一方でMarkdownは文法が簡単なので，箇条書きでメモってるぐらいの感覚で構造を持った文章が書けてしまいます．Hugoを使うことで，サイト作成者はMarkdownというわかりやすい文法で記事を書くことができ，本来の仕事に専念できるわけです．\nHugoのいいところはそれだけではありません．Hugoはその便利さから，多くのユーザーから愛されていて，そのユーザーらがそれぞれ美しいデザインテーマを公開してくれています．どれもセンスが良く，機能面でも充実しています．このテーマはオープンソースで公開されているので，カスタマイズも簡単です．そこらへんのブログサービスを利用すると，テーマがどれも陳腐で不満ですよね．\n今回はMarkdownで記事が執筆できるところとHugoで用いることができるAcademicというテーマが気に入ったので，Hugoを使うことにしました．\nGitHub Pagesは，GitHubが提供している静的サイトのホスティングサービスです．GitHubのアカウントさえあれば，誰でも静的なサイトを公開することができます．何より無料なので，これを使わない手はありません．サイトのソースコードをGitHubで管理しつつ公開もできちゃうなんて，GitHubは太っ腹ですね．\nGitHub Pagesの他にもホスティングサービスはありますが，ソースコード管理と一緒にホスティングできるところが便利だと思ったので採用しました．\n 気が向いたら，もうちょっと追記します 🙇\n ","date":1571991698,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1571991698,"objectID":"7c7a7a98c108a8c69ca3bde923f50c92","permalink":"/post/about-this-site/","publishdate":"2019-10-25T17:21:38+09:00","relpermalink":"/post/about-this-site/","section":"post","summary":"このブログの技術的なところをまとめてみました！まだ途中です :bow:","tags":["Hugo","GitHub","Golang"],"title":"HugoとGitHub Pagesでブログを作ってみた！","type":"post"},{"authors":[],"categories":[],"content":" ご挨拶 はじめまして．技術ブログ始めてみました．ぼちぼち投稿します 👍\n","date":1571990829,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1571990829,"objectID":"2247257f33c5eaa1cd0616bf37b07249","permalink":"/post/first-post/","publishdate":"2019-10-25T17:07:09+09:00","relpermalink":"/post/first-post/","section":"post","summary":"ブログを始めてみたのでお知らせです．","tags":[],"title":"🚀最初の投稿","type":"post"}]